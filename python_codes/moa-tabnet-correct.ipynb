{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-output": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2020-11-20T06:28:06.687479Z",
     "iopub.status.busy": "2020-11-20T06:28:06.686641Z",
     "iopub.status.idle": "2020-11-20T06:28:16.367467Z",
     "shell.execute_reply": "2020-11-20T06:28:16.365750Z"
    },
    "papermill": {
     "duration": 9.723567,
     "end_time": "2020-11-20T06:28:16.367601",
     "exception": false,
     "start_time": "2020-11-20T06:28:06.644034",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: /kaggle/input/pytorchtabnet/pytorch_tabnet-2.0.0-py3-none-any.whl\r\n",
      "Processing /kaggle/input/pytorchtabnet/pytorch_tabnet-2.0.0-py3-none-any.whl\r\n",
      "Requirement already satisfied: torch<2.0,>=1.2 in /opt/conda/lib/python3.7/site-packages (from pytorch-tabnet) (1.6.0)\r\n",
      "Requirement already satisfied: tqdm<5.0,>=4.36 in /opt/conda/lib/python3.7/site-packages (from pytorch-tabnet) (4.45.0)\r\n",
      "Requirement already satisfied: scipy>1.4 in /opt/conda/lib/python3.7/site-packages (from pytorch-tabnet) (1.4.1)\r\n",
      "Requirement already satisfied: numpy<2.0,>=1.17 in /opt/conda/lib/python3.7/site-packages (from pytorch-tabnet) (1.18.5)\r\n",
      "Requirement already satisfied: scikit_learn>0.21 in /opt/conda/lib/python3.7/site-packages (from pytorch-tabnet) (0.23.2)\r\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from torch<2.0,>=1.2->pytorch-tabnet) (0.18.2)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit_learn>0.21->pytorch-tabnet) (2.1.0)\r\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit_learn>0.21->pytorch-tabnet) (0.14.1)\r\n",
      "Installing collected packages: pytorch-tabnet\r\n",
      "Successfully installed pytorch-tabnet-2.0.0\r\n"
     ]
    }
   ],
   "source": [
    "# TabNet\n",
    "!pip install --no-index --find-links /kaggle/input/pytorchtabnet/pytorch_tabnet-2.0.0-py3-none-any.whl pytorch-tabnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-20T06:28:16.438370Z",
     "iopub.status.busy": "2020-11-20T06:28:16.437372Z",
     "iopub.status.idle": "2020-11-20T06:28:17.321496Z",
     "shell.execute_reply": "2020-11-20T06:28:17.320839Z"
    },
    "papermill": {
     "duration": 0.921676,
     "end_time": "2020-11-20T06:28:17.321633",
     "exception": false,
     "start_time": "2020-11-20T06:28:16.399957",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../input/iterativestratification')\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2020-11-20T06:28:17.396796Z",
     "iopub.status.busy": "2020-11-20T06:28:17.396021Z",
     "iopub.status.idle": "2020-11-20T06:28:18.816503Z",
     "shell.execute_reply": "2020-11-20T06:28:18.815566Z"
    },
    "papermill": {
     "duration": 1.463973,
     "end_time": "2020-11-20T06:28:18.816627",
     "exception": false,
     "start_time": "2020-11-20T06:28:17.352654",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "### General ###\n",
    "import os\n",
    "import copy\n",
    "import tqdm\n",
    "import pickle\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = '1'\n",
    "\n",
    "### Data Wrangling ###\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "### Machine Learning ###\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import roc_auc_score, log_loss\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "### Deep Learning ###\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torch.nn import functional as F\n",
    "from torch.nn.modules.loss import _WeightedLoss\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "# Tabnet \n",
    "from pytorch_tabnet.metrics import Metric\n",
    "from pytorch_tabnet.tab_model import TabNetRegressor\n",
    "\n",
    "from pickle import load,dump\n",
    "\n",
    "### Make prettier the prints ###\n",
    "from colorama import Fore\n",
    "c_ = Fore.CYAN\n",
    "m_ = Fore.MAGENTA\n",
    "r_ = Fore.RED\n",
    "b_ = Fore.BLUE\n",
    "y_ = Fore.YELLOW\n",
    "g_ = Fore.GREEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-20T06:28:18.893942Z",
     "iopub.status.busy": "2020-11-20T06:28:18.892978Z",
     "iopub.status.idle": "2020-11-20T06:28:18.895946Z",
     "shell.execute_reply": "2020-11-20T06:28:18.895444Z"
    },
    "papermill": {
     "duration": 0.03871,
     "end_time": "2020-11-20T06:28:18.896049",
     "exception": false,
     "start_time": "2020-11-20T06:28:18.857339",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import QuantileTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-20T06:28:18.963339Z",
     "iopub.status.busy": "2020-11-20T06:28:18.961673Z",
     "iopub.status.idle": "2020-11-20T06:28:18.969826Z",
     "shell.execute_reply": "2020-11-20T06:28:18.969278Z"
    },
    "papermill": {
     "duration": 0.042983,
     "end_time": "2020-11-20T06:28:18.969943",
     "exception": false,
     "start_time": "2020-11-20T06:28:18.926960",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test_features.csv',\n",
       " 'train_drug.csv',\n",
       " 'train_features.csv',\n",
       " 'train_targets_scored.csv',\n",
       " 'train_targets_nonscored.csv',\n",
       " 'sample_submission.csv']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('../input/lish-moa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-20T06:28:19.041745Z",
     "iopub.status.busy": "2020-11-20T06:28:19.040823Z",
     "iopub.status.idle": "2020-11-20T06:28:25.989986Z",
     "shell.execute_reply": "2020-11-20T06:28:25.988665Z"
    },
    "papermill": {
     "duration": 6.98813,
     "end_time": "2020-11-20T06:28:25.990124",
     "exception": false,
     "start_time": "2020-11-20T06:28:19.001994",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_features = pd.read_csv('../input/lish-moa/train_features.csv')\n",
    "train_targets_scored = pd.read_csv('../input/lish-moa/train_targets_scored.csv')\n",
    "train_targets_nonscored = pd.read_csv('../input/lish-moa/train_targets_nonscored.csv')\n",
    "\n",
    "test_features = pd.read_csv('../input/lish-moa/test_features.csv')\n",
    "df = pd.read_csv('../input/lish-moa/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-20T06:28:26.062499Z",
     "iopub.status.busy": "2020-11-20T06:28:26.061158Z",
     "iopub.status.idle": "2020-11-20T06:28:26.137187Z",
     "shell.execute_reply": "2020-11-20T06:28:26.136560Z"
    },
    "papermill": {
     "duration": 0.113659,
     "end_time": "2020-11-20T06:28:26.137309",
     "exception": false,
     "start_time": "2020-11-20T06:28:26.023650",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_features2=train_features.copy()\n",
    "test_features2=test_features.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-20T06:28:26.231249Z",
     "iopub.status.busy": "2020-11-20T06:28:26.229260Z",
     "iopub.status.idle": "2020-11-20T06:28:26.232025Z",
     "shell.execute_reply": "2020-11-20T06:28:26.232618Z"
    },
    "papermill": {
     "duration": 0.061199,
     "end_time": "2020-11-20T06:28:26.232751",
     "exception": false,
     "start_time": "2020-11-20T06:28:26.171552",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "GENES = [col for col in train_features.columns if col.startswith('g-')]\n",
    "CELLS = [col for col in train_features.columns if col.startswith('c-')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-20T06:28:26.310302Z",
     "iopub.status.busy": "2020-11-20T06:28:26.309508Z",
     "iopub.status.idle": "2020-11-20T06:28:42.922278Z",
     "shell.execute_reply": "2020-11-20T06:28:42.921574Z"
    },
    "papermill": {
     "duration": 16.65654,
     "end_time": "2020-11-20T06:28:42.922414",
     "exception": false,
     "start_time": "2020-11-20T06:28:26.265874",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "qt = QuantileTransformer(n_quantiles=100,random_state=42,output_distribution='normal')\n",
    "train_features[GENES+CELLS] = qt.fit_transform(train_features[GENES+CELLS])\n",
    "test_features[GENES+CELLS] = qt.transform(test_features[GENES+CELLS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-20T06:28:42.996994Z",
     "iopub.status.busy": "2020-11-20T06:28:42.996257Z",
     "iopub.status.idle": "2020-11-20T06:28:43.381024Z",
     "shell.execute_reply": "2020-11-20T06:28:43.380385Z"
    },
    "papermill": {
     "duration": 0.424621,
     "end_time": "2020-11-20T06:28:43.381138",
     "exception": false,
     "start_time": "2020-11-20T06:28:42.956517",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "seed = 42\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-20T06:28:43.462411Z",
     "iopub.status.busy": "2020-11-20T06:28:43.460941Z",
     "iopub.status.idle": "2020-11-20T06:28:56.402392Z",
     "shell.execute_reply": "2020-11-20T06:28:56.401580Z"
    },
    "papermill": {
     "duration": 12.987573,
     "end_time": "2020-11-20T06:28:56.402529",
     "exception": false,
     "start_time": "2020-11-20T06:28:43.414956",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_comp = 600  #<--Update\n",
    "pca_g = PCA(n_components=n_comp, random_state=42)\n",
    "data = pd.concat([pd.DataFrame(train_features[GENES]), pd.DataFrame(test_features[GENES])])\n",
    "gpca= (pca_g.fit(data[GENES]))\n",
    "train2= (gpca.transform(train_features[GENES]))\n",
    "test2 = (gpca.transform(test_features[GENES]))\n",
    "\n",
    "train_gpca = pd.DataFrame(train2, columns=[f'pca_G-{i}' for i in range(n_comp)])\n",
    "test_gpca = pd.DataFrame(test2, columns=[f'pca_G-{i}' for i in range(n_comp)])\n",
    "\n",
    "# drop_cols = [f'c-{i}' for i in range(n_comp,len(GENES))]\n",
    "train_features = pd.concat((train_features, train_gpca), axis=1)\n",
    "test_features = pd.concat((test_features, test_gpca), axis=1)\n",
    "\n",
    "dump(gpca, open('gpca.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-20T06:28:56.483572Z",
     "iopub.status.busy": "2020-11-20T06:28:56.482354Z",
     "iopub.status.idle": "2020-11-20T06:28:57.257152Z",
     "shell.execute_reply": "2020-11-20T06:28:57.256544Z"
    },
    "papermill": {
     "duration": 0.820003,
     "end_time": "2020-11-20T06:28:57.257280",
     "exception": false,
     "start_time": "2020-11-20T06:28:56.437277",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#CELLS\n",
    "n_comp = 50  #<--Update\n",
    "\n",
    "pca_c = PCA(n_components=n_comp, random_state=42)\n",
    "data = pd.concat([pd.DataFrame(train_features[CELLS]), pd.DataFrame(test_features[CELLS])])\n",
    "cpca= (pca_c.fit(data[CELLS]))\n",
    "train2= (cpca.transform(train_features[CELLS]))\n",
    "test2 = (cpca.transform(test_features[CELLS]))\n",
    "\n",
    "train_cpca = pd.DataFrame(train2, columns=[f'pca_C-{i}' for i in range(n_comp)])\n",
    "test_cpca = pd.DataFrame(test2, columns=[f'pca_C-{i}' for i in range(n_comp)])\n",
    "\n",
    "# drop_cols = [f'c-{i}' for i in range(n_comp,len(CELLS))]\n",
    "train_features = pd.concat((train_features, train_cpca), axis=1)\n",
    "test_features = pd.concat((test_features, test_cpca), axis=1)\n",
    "\n",
    "dump(cpca, open('cpca.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-20T06:28:57.332847Z",
     "iopub.status.busy": "2020-11-20T06:28:57.332091Z",
     "iopub.status.idle": "2020-11-20T06:28:58.117442Z",
     "shell.execute_reply": "2020-11-20T06:28:58.116394Z"
    },
    "papermill": {
     "duration": 0.827013,
     "end_time": "2020-11-20T06:28:58.117595",
     "exception": false,
     "start_time": "2020-11-20T06:28:57.290582",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "c_n = [f for f in list(train_features.columns) if f not in ['sig_id', 'cp_type', 'cp_time', 'cp_dose']]\n",
    "mask = (train_features[c_n].var() >= 0.85).values\n",
    "tmp = train_features[c_n].loc[:, mask]\n",
    "train_features = pd.concat([train_features[['sig_id', 'cp_type', 'cp_time', 'cp_dose']], tmp], axis=1)\n",
    "tmp = test_features[c_n].loc[:, mask]\n",
    "test_features = pd.concat([test_features[['sig_id', 'cp_type', 'cp_time', 'cp_dose']], tmp], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-20T06:28:58.218672Z",
     "iopub.status.busy": "2020-11-20T06:28:58.217860Z",
     "iopub.status.idle": "2020-11-20T06:29:46.486802Z",
     "shell.execute_reply": "2020-11-20T06:29:46.485518Z"
    },
    "papermill": {
     "duration": 48.329144,
     "end_time": "2020-11-20T06:29:46.486932",
     "exception": false,
     "start_time": "2020-11-20T06:28:58.157788",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "def fe_cluster_genes(train, test, n_clusters_g = 22, SEED = 42):\n",
    "    \n",
    "    features_g = GENES\n",
    "    #features_c = CELLS\n",
    "    \n",
    "    def create_cluster(train, test, features, kind = 'g', n_clusters = n_clusters_g):\n",
    "        train_ = train[features].copy()\n",
    "        test_ = test[features].copy()\n",
    "        data = pd.concat([train_, test_], axis = 0)\n",
    "        kmeans_genes = KMeans(n_clusters = n_clusters, random_state = SEED).fit(data)\n",
    "        dump(kmeans_genes, open('kmeans_genes.pkl', 'wb'))\n",
    "        train[f'clusters_{kind}'] = kmeans_genes.predict(train_.values)\n",
    "        test[f'clusters_{kind}'] = kmeans_genes.predict(test_.values)\n",
    "        train = pd.get_dummies(train, columns = [f'clusters_{kind}'])\n",
    "        test = pd.get_dummies(test, columns = [f'clusters_{kind}'])\n",
    "        return train, test\n",
    "    \n",
    "    train, test = create_cluster(train, test, features_g, kind = 'g', n_clusters = n_clusters_g)\n",
    "   # train, test = create_cluster(train, test, features_c, kind = 'c', n_clusters = n_clusters_c)\n",
    "    return train, test\n",
    "\n",
    "train_features2 ,test_features2=fe_cluster_genes(train_features2,test_features2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-20T06:29:46.571467Z",
     "iopub.status.busy": "2020-11-20T06:29:46.569705Z",
     "iopub.status.idle": "2020-11-20T06:29:48.281596Z",
     "shell.execute_reply": "2020-11-20T06:29:48.280946Z"
    },
    "papermill": {
     "duration": 1.760166,
     "end_time": "2020-11-20T06:29:48.281715",
     "exception": false,
     "start_time": "2020-11-20T06:29:46.521549",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fe_cluster_cells(train, test, n_clusters_c = 4, SEED = 42):\n",
    "    \n",
    "    #features_g = GENES\n",
    "    features_c = CELLS\n",
    "    \n",
    "    def create_cluster(train, test, features, kind = 'c', n_clusters = n_clusters_c):\n",
    "        train_ = train[features].copy()\n",
    "        test_ = test[features].copy()\n",
    "        data = pd.concat([train_, test_], axis = 0)\n",
    "        kmeans_cells = KMeans(n_clusters = n_clusters, random_state = SEED).fit(data)\n",
    "        dump(kmeans_cells, open('kmeans_cells.pkl', 'wb'))\n",
    "        train[f'clusters_{kind}'] = kmeans_cells.predict(train_.values)\n",
    "        test[f'clusters_{kind}'] = kmeans_cells.predict(test_.values)\n",
    "        train = pd.get_dummies(train, columns = [f'clusters_{kind}'])\n",
    "        test = pd.get_dummies(test, columns = [f'clusters_{kind}'])\n",
    "        return train, test\n",
    "    \n",
    "   # train, test = create_cluster(train, test, features_g, kind = 'g', n_clusters = n_clusters_g)\n",
    "    train, test = create_cluster(train, test, features_c, kind = 'c', n_clusters = n_clusters_c)\n",
    "    return train, test\n",
    "\n",
    "train_features2 ,test_features2=fe_cluster_cells(train_features2,test_features2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-20T06:29:48.359064Z",
     "iopub.status.busy": "2020-11-20T06:29:48.357759Z",
     "iopub.status.idle": "2020-11-20T06:29:48.458492Z",
     "shell.execute_reply": "2020-11-20T06:29:48.457864Z"
    },
    "papermill": {
     "duration": 0.141913,
     "end_time": "2020-11-20T06:29:48.458612",
     "exception": false,
     "start_time": "2020-11-20T06:29:48.316699",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_pca=pd.concat((train_gpca,train_cpca),axis=1)\n",
    "test_pca=pd.concat((test_gpca,test_cpca),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-20T06:29:48.539826Z",
     "iopub.status.busy": "2020-11-20T06:29:48.538512Z",
     "iopub.status.idle": "2020-11-20T06:30:04.678813Z",
     "shell.execute_reply": "2020-11-20T06:30:04.678027Z"
    },
    "papermill": {
     "duration": 16.185439,
     "end_time": "2020-11-20T06:30:04.678947",
     "exception": false,
     "start_time": "2020-11-20T06:29:48.493508",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fe_cluster_pca(train, test,n_clusters=5,SEED = 42):\n",
    "        data=pd.concat([train,test],axis=0)\n",
    "        kmeans_pca = KMeans(n_clusters = n_clusters, random_state = SEED).fit(data)\n",
    "        dump(kmeans_pca, open('kmeans_pca.pkl', 'wb'))\n",
    "        train[f'clusters_pca'] = kmeans_pca.predict(train.values)\n",
    "        test[f'clusters_pca'] = kmeans_pca.predict(test.values)\n",
    "        train = pd.get_dummies(train, columns = [f'clusters_pca'])\n",
    "        test = pd.get_dummies(test, columns = [f'clusters_pca'])\n",
    "        return train, test\n",
    "train_cluster_pca ,test_cluster_pca = fe_cluster_pca(train_pca,test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-20T06:30:04.755470Z",
     "iopub.status.busy": "2020-11-20T06:30:04.753527Z",
     "iopub.status.idle": "2020-11-20T06:30:04.758939Z",
     "shell.execute_reply": "2020-11-20T06:30:04.758358Z"
    },
    "papermill": {
     "duration": 0.045001,
     "end_time": "2020-11-20T06:30:04.759045",
     "exception": false,
     "start_time": "2020-11-20T06:30:04.714044",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_cluster_pca = train_cluster_pca.iloc[:,650:]\n",
    "test_cluster_pca = test_cluster_pca.iloc[:,650:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-20T06:30:04.831378Z",
     "iopub.status.busy": "2020-11-20T06:30:04.829997Z",
     "iopub.status.idle": "2020-11-20T06:30:04.833797Z",
     "shell.execute_reply": "2020-11-20T06:30:04.834338Z"
    },
    "papermill": {
     "duration": 0.041724,
     "end_time": "2020-11-20T06:30:04.834465",
     "exception": false,
     "start_time": "2020-11-20T06:30:04.792741",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_features_cluster=train_features2.iloc[:,876:]\n",
    "test_features_cluster=test_features2.iloc[:,876:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-20T06:30:04.909575Z",
     "iopub.status.busy": "2020-11-20T06:30:04.907560Z",
     "iopub.status.idle": "2020-11-20T06:30:04.910258Z",
     "shell.execute_reply": "2020-11-20T06:30:04.910722Z"
    },
    "papermill": {
     "duration": 0.042766,
     "end_time": "2020-11-20T06:30:04.910827",
     "exception": false,
     "start_time": "2020-11-20T06:30:04.868061",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "gsquarecols=['g-574','g-211','g-216','g-0','g-255','g-577','g-153','g-389','g-60','g-370','g-248','g-167','g-203','g-177','g-301','g-332','g-517','g-6','g-744','g-224','g-162','g-3','g-736','g-486','g-283','g-22','g-359','g-361','g-440','g-335','g-106','g-307','g-745','g-146','g-416','g-298','g-666','g-91','g-17','g-549','g-145','g-157','g-768','g-568','g-396']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-20T06:30:05.004631Z",
     "iopub.status.busy": "2020-11-20T06:30:05.002972Z",
     "iopub.status.idle": "2020-11-20T06:30:11.433573Z",
     "shell.execute_reply": "2020-11-20T06:30:11.434645Z"
    },
    "papermill": {
     "duration": 6.491036,
     "end_time": "2020-11-20T06:30:11.434883",
     "exception": false,
     "start_time": "2020-11-20T06:30:04.943847",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fe_stats(train, test):\n",
    "    \n",
    "    features_g = GENES\n",
    "    features_c = CELLS\n",
    "    \n",
    "    for df in train, test:\n",
    "        df['g_sum'] = df[features_g].sum(axis = 1)\n",
    "        df['g_mean'] = df[features_g].mean(axis = 1)\n",
    "        df['g_std'] = df[features_g].std(axis = 1)\n",
    "        df['g_kurt'] = df[features_g].kurtosis(axis = 1)\n",
    "        df['g_skew'] = df[features_g].skew(axis = 1)\n",
    "        df['c_sum'] = df[features_c].sum(axis = 1)\n",
    "        df['c_mean'] = df[features_c].mean(axis = 1)\n",
    "        df['c_std'] = df[features_c].std(axis = 1)\n",
    "        df['c_kurt'] = df[features_c].kurtosis(axis = 1)\n",
    "        df['c_skew'] = df[features_c].skew(axis = 1)\n",
    "        df['gc_sum'] = df[features_g + features_c].sum(axis = 1)\n",
    "        df['gc_mean'] = df[features_g + features_c].mean(axis = 1)\n",
    "        df['gc_std'] = df[features_g + features_c].std(axis = 1)\n",
    "        df['gc_kurt'] = df[features_g + features_c].kurtosis(axis = 1)\n",
    "        df['gc_skew'] = df[features_g + features_c].skew(axis = 1)\n",
    "        \n",
    "        df['c52_c42'] = df['c-52'] * df['c-42']\n",
    "        df['c13_c73'] = df['c-13'] * df['c-73']\n",
    "        df['c26_c13'] = df['c-23'] * df['c-13']\n",
    "        df['c33_c6'] = df['c-33'] * df['c-6']\n",
    "        df['c11_c55'] = df['c-11'] * df['c-55']\n",
    "        df['c38_c63'] = df['c-38'] * df['c-63']\n",
    "        df['c38_c94'] = df['c-38'] * df['c-94']\n",
    "        df['c13_c94'] = df['c-13'] * df['c-94']\n",
    "        df['c4_c52'] = df['c-4'] * df['c-52']\n",
    "        df['c4_c42'] = df['c-4'] * df['c-42']\n",
    "        df['c13_c38'] = df['c-13'] * df['c-38']\n",
    "        df['c55_c2'] = df['c-55'] * df['c-2']\n",
    "        df['c55_c4'] = df['c-55'] * df['c-4']\n",
    "        df['c4_c13'] = df['c-4'] * df['c-13']\n",
    "        df['c82_c42'] = df['c-82'] * df['c-42']\n",
    "        df['c66_c42'] = df['c-66'] * df['c-42']\n",
    "        df['c6_c38'] = df['c-6'] * df['c-38']\n",
    "        df['c2_c13'] = df['c-2'] * df['c-13']\n",
    "        df['c62_c42'] = df['c-62'] * df['c-42']\n",
    "        df['c90_c55'] = df['c-90'] * df['c-55']\n",
    "        \n",
    "        \n",
    "        for feature in features_c:\n",
    "             df[f'{feature}_squared'] = df[feature] ** 2     \n",
    "                \n",
    "        for feature in gsquarecols:\n",
    "            df[f'{feature}_squared'] = df[feature] ** 2        \n",
    "        \n",
    "    return train, test\n",
    "\n",
    "train_features2,test_features2=fe_stats(train_features2,test_features2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-20T06:30:11.551354Z",
     "iopub.status.busy": "2020-11-20T06:30:11.550613Z",
     "iopub.status.idle": "2020-11-20T06:30:11.554299Z",
     "shell.execute_reply": "2020-11-20T06:30:11.553738Z"
    },
    "papermill": {
     "duration": 0.066954,
     "end_time": "2020-11-20T06:30:11.554412",
     "exception": false,
     "start_time": "2020-11-20T06:30:11.487458",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_features_stats=train_features2.iloc[:,902:]\n",
    "test_features_stats=test_features2.iloc[:,902:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-20T06:30:11.629398Z",
     "iopub.status.busy": "2020-11-20T06:30:11.628416Z",
     "iopub.status.idle": "2020-11-20T06:30:11.759307Z",
     "shell.execute_reply": "2020-11-20T06:30:11.758719Z"
    },
    "papermill": {
     "duration": 0.170024,
     "end_time": "2020-11-20T06:30:11.759440",
     "exception": false,
     "start_time": "2020-11-20T06:30:11.589416",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_features = pd.concat((train_features, train_features_cluster,train_cluster_pca,train_features_stats), axis=1)\n",
    "test_features = pd.concat((test_features, test_features_cluster,test_cluster_pca,test_features_stats), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-20T06:30:11.836894Z",
     "iopub.status.busy": "2020-11-20T06:30:11.835668Z",
     "iopub.status.idle": "2020-11-20T06:30:12.535496Z",
     "shell.execute_reply": "2020-11-20T06:30:12.536811Z"
    },
    "papermill": {
     "duration": 0.742608,
     "end_time": "2020-11-20T06:30:12.537015",
     "exception": false,
     "start_time": "2020-11-20T06:30:11.794407",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = train_features.merge(train_targets_scored, on='sig_id')\n",
    "train = train[train['cp_type']!='ctl_vehicle'].reset_index(drop=True)\n",
    "test = test_features[test_features['cp_type']!='ctl_vehicle'].reset_index(drop=True)\n",
    "\n",
    "target = train[train_targets_scored.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-20T06:30:12.642873Z",
     "iopub.status.busy": "2020-11-20T06:30:12.642057Z",
     "iopub.status.idle": "2020-11-20T06:30:12.763976Z",
     "shell.execute_reply": "2020-11-20T06:30:12.764511Z"
    },
    "papermill": {
     "duration": 0.177723,
     "end_time": "2020-11-20T06:30:12.764665",
     "exception": false,
     "start_time": "2020-11-20T06:30:12.586942",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = train.drop('cp_type', axis=1)\n",
    "test = test.drop('cp_type', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-20T06:30:12.861446Z",
     "iopub.status.busy": "2020-11-20T06:30:12.859634Z",
     "iopub.status.idle": "2020-11-20T06:30:12.862262Z",
     "shell.execute_reply": "2020-11-20T06:30:12.862744Z"
    },
    "papermill": {
     "duration": 0.055978,
     "end_time": "2020-11-20T06:30:12.862867",
     "exception": false,
     "start_time": "2020-11-20T06:30:12.806889",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_cols = target.drop('sig_id', axis=1).columns.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-20T06:30:12.949445Z",
     "iopub.status.busy": "2020-11-20T06:30:12.948617Z",
     "iopub.status.idle": "2020-11-20T06:30:12.952144Z",
     "shell.execute_reply": "2020-11-20T06:30:12.951612Z"
    },
    "papermill": {
     "duration": 0.054183,
     "end_time": "2020-11-20T06:30:12.952274",
     "exception": false,
     "start_time": "2020-11-20T06:30:12.898091",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "target=target[target_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-20T06:30:13.027712Z",
     "iopub.status.busy": "2020-11-20T06:30:13.025429Z",
     "iopub.status.idle": "2020-11-20T06:30:13.221945Z",
     "shell.execute_reply": "2020-11-20T06:30:13.221372Z"
    },
    "papermill": {
     "duration": 0.236065,
     "end_time": "2020-11-20T06:30:13.222076",
     "exception": false,
     "start_time": "2020-11-20T06:30:12.986011",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.get_dummies(train, columns=['cp_time','cp_dose'])\n",
    "test_ = pd.get_dummies(test, columns=['cp_time','cp_dose'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-20T06:30:13.304421Z",
     "iopub.status.busy": "2020-11-20T06:30:13.303645Z",
     "iopub.status.idle": "2020-11-20T06:30:13.307418Z",
     "shell.execute_reply": "2020-11-20T06:30:13.306862Z"
    },
    "papermill": {
     "duration": 0.048871,
     "end_time": "2020-11-20T06:30:13.307515",
     "exception": false,
     "start_time": "2020-11-20T06:30:13.258644",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_cols = [c for c in train.columns if c not in target_cols]\n",
    "feature_cols = [c for c in feature_cols if c not in ['sig_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-20T06:30:13.383869Z",
     "iopub.status.busy": "2020-11-20T06:30:13.382589Z",
     "iopub.status.idle": "2020-11-20T06:30:13.625915Z",
     "shell.execute_reply": "2020-11-20T06:30:13.625153Z"
    },
    "papermill": {
     "duration": 0.284075,
     "end_time": "2020-11-20T06:30:13.626025",
     "exception": false,
     "start_time": "2020-11-20T06:30:13.341950",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = train[feature_cols]\n",
    "test = test_[feature_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-20T06:30:13.702884Z",
     "iopub.status.busy": "2020-11-20T06:30:13.701578Z",
     "iopub.status.idle": "2020-11-20T06:30:13.717741Z",
     "shell.execute_reply": "2020-11-20T06:30:13.717135Z"
    },
    "papermill": {
     "duration": 0.055239,
     "end_time": "2020-11-20T06:30:13.717867",
     "exception": false,
     "start_time": "2020-11-20T06:30:13.662628",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_test = test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-20T06:30:13.803010Z",
     "iopub.status.busy": "2020-11-20T06:30:13.801558Z",
     "iopub.status.idle": "2020-11-20T06:30:13.804213Z",
     "shell.execute_reply": "2020-11-20T06:30:13.804710Z"
    },
    "papermill": {
     "duration": 0.050802,
     "end_time": "2020-11-20T06:30:13.804825",
     "exception": false,
     "start_time": "2020-11-20T06:30:13.754023",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.nn.modules.loss import _WeightedLoss\n",
    "class SmoothBCEwLogits(_WeightedLoss):\n",
    "    def __init__(self, weight=None, reduction='mean', smoothing=0.0):\n",
    "        super().__init__(weight=weight, reduction=reduction)\n",
    "        self.smoothing = smoothing\n",
    "        self.weight = weight\n",
    "        self.reduction = reduction\n",
    "\n",
    "    @staticmethod\n",
    "    def _smooth(targets:torch.Tensor, n_labels:int, smoothing=0.0):\n",
    "        assert 0 <= smoothing < 1\n",
    "        with torch.no_grad():\n",
    "            targets = targets * (1.0 - smoothing) + 0.5 * smoothing\n",
    "        return targets\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        targets = SmoothBCEwLogits._smooth(targets, inputs.size(-1),\n",
    "            self.smoothing)\n",
    "        loss = F.binary_cross_entropy_with_logits(inputs, targets,self.weight)\n",
    "\n",
    "        if  self.reduction == 'sum':\n",
    "            loss = loss.sum()\n",
    "        elif  self.reduction == 'mean':\n",
    "            loss = loss.mean()\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-20T06:30:13.882049Z",
     "iopub.status.busy": "2020-11-20T06:30:13.881470Z",
     "iopub.status.idle": "2020-11-20T06:30:13.885834Z",
     "shell.execute_reply": "2020-11-20T06:30:13.885349Z"
    },
    "papermill": {
     "duration": 0.045443,
     "end_time": "2020-11-20T06:30:13.885930",
     "exception": false,
     "start_time": "2020-11-20T06:30:13.840487",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LogitsLogLoss(Metric):\n",
    "\n",
    "    def __init__(self):\n",
    "        self._name = \"logits_ll\"\n",
    "        self._maximize = False\n",
    "\n",
    "    def __call__(self, y_true, y_pred):\n",
    "        logits = 1 / (1 + np.exp(-y_pred))\n",
    "        aux = (1 - y_true) * np.log(1 - logits + 5e-5) + y_true * np.log(logits + 5e-5)\n",
    "        return np.mean(-aux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-20T06:30:13.961731Z",
     "iopub.status.busy": "2020-11-20T06:30:13.960978Z",
     "iopub.status.idle": "2020-11-20T06:30:13.964414Z",
     "shell.execute_reply": "2020-11-20T06:30:13.964875Z"
    },
    "papermill": {
     "duration": 0.045019,
     "end_time": "2020-11-20T06:30:13.964991",
     "exception": false,
     "start_time": "2020-11-20T06:30:13.919972",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "MAX_EPOCH = 200\n",
    "\n",
    "tabnet_params = dict(\n",
    "    n_d = 32,\n",
    "    n_a = 32,\n",
    "    n_steps = 1,\n",
    "    gamma = 1.3,\n",
    "    lambda_sparse = 0,\n",
    "    optimizer_fn = optim.Adam,\n",
    "    optimizer_params = dict(lr = 2e-2, weight_decay = 1e-5),\n",
    "    mask_type = \"entmax\",\n",
    "    scheduler_params = dict(mode = \"min\", patience = 5, min_lr = 1e-5, factor = 0.9),\n",
    "    scheduler_fn = ReduceLROnPlateau,\n",
    "    seed = seed,\n",
    "    verbose = 10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-20T06:30:14.059863Z",
     "iopub.status.busy": "2020-11-20T06:30:14.047880Z",
     "iopub.status.idle": "2020-11-20T08:40:20.182208Z",
     "shell.execute_reply": "2020-11-20T08:40:20.181574Z"
    },
    "papermill": {
     "duration": 7806.183375,
     "end_time": "2020-11-20T08:40:20.182370",
     "exception": false,
     "start_time": "2020-11-20T06:30:13.998995",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m FOLDS:  \u001b[31m 1 \u001b[33m seed: 20\n",
      "\u001b[32m ************************************************************ \u001b[36m\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.3333  | val_logits_ll: 0.03114 |  0:00:02s\n",
      "epoch 10 | loss: 0.01888 | val_logits_ll: 0.01872 |  0:00:25s\n",
      "epoch 20 | loss: 0.01743 | val_logits_ll: 0.01843 |  0:00:48s\n",
      "epoch 30 | loss: 0.01709 | val_logits_ll: 0.0173  |  0:01:11s\n",
      "epoch 40 | loss: 0.01673 | val_logits_ll: 0.0167  |  0:01:33s\n",
      "epoch 50 | loss: 0.01648 | val_logits_ll: 0.01686 |  0:01:56s\n",
      "epoch 60 | loss: 0.01632 | val_logits_ll: 0.01681 |  0:02:19s\n",
      "epoch 70 | loss: 0.01593 | val_logits_ll: 0.0165  |  0:02:42s\n",
      "epoch 80 | loss: 0.01573 | val_logits_ll: 0.01662 |  0:03:05s\n",
      "epoch 90 | loss: 0.01524 | val_logits_ll: 0.01655 |  0:03:28s\n",
      "\n",
      "Early stopping occured at epoch 90 with best_epoch = 70 and best_val_logits_ll = 0.0165\n",
      "Best weights from best epoch are automatically used!\n",
      "\u001b[33m ------------------------------------------------------------\n",
      "Successfully saved model at TabNet_seed_20_fold_1.zip\n",
      "Device used : cuda\n",
      "Device used : cuda\n",
      "Device used : cuda\n",
      "\u001b[34m FOLDS:  \u001b[31m 2 \u001b[33m seed: 20\n",
      "\u001b[32m ************************************************************ \u001b[36m\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.33365 | val_logits_ll: 0.03181 |  0:00:02s\n",
      "epoch 10 | loss: 0.01929 | val_logits_ll: 0.02157 |  0:00:25s\n",
      "epoch 20 | loss: 0.01768 | val_logits_ll: 0.01844 |  0:00:47s\n",
      "epoch 30 | loss: 0.01723 | val_logits_ll: 0.01777 |  0:01:09s\n",
      "epoch 40 | loss: 0.01677 | val_logits_ll: 0.01681 |  0:01:32s\n",
      "epoch 50 | loss: 0.0165  | val_logits_ll: 0.01803 |  0:01:53s\n",
      "epoch 60 | loss: 0.01634 | val_logits_ll: 0.0169  |  0:02:16s\n",
      "epoch 70 | loss: 0.01606 | val_logits_ll: 0.01665 |  0:02:37s\n",
      "epoch 80 | loss: 0.01574 | val_logits_ll: 0.01637 |  0:02:59s\n",
      "epoch 90 | loss: 0.01555 | val_logits_ll: 0.01677 |  0:03:21s\n",
      "epoch 100| loss: 0.01518 | val_logits_ll: 0.01671 |  0:03:42s\n",
      "\n",
      "Early stopping occured at epoch 100 with best_epoch = 80 and best_val_logits_ll = 0.01637\n",
      "Best weights from best epoch are automatically used!\n",
      "\u001b[33m ------------------------------------------------------------\n",
      "Successfully saved model at TabNet_seed_20_fold_2.zip\n",
      "Device used : cuda\n",
      "Device used : cuda\n",
      "Device used : cuda\n",
      "\u001b[34m FOLDS:  \u001b[31m 3 \u001b[33m seed: 20\n",
      "\u001b[32m ************************************************************ \u001b[36m\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.33048 | val_logits_ll: 0.03017 |  0:00:02s\n",
      "epoch 10 | loss: 0.01912 | val_logits_ll: 0.0187  |  0:00:23s\n",
      "epoch 20 | loss: 0.01782 | val_logits_ll: 0.02069 |  0:00:46s\n",
      "epoch 30 | loss: 0.01709 | val_logits_ll: 0.01725 |  0:01:08s\n",
      "epoch 40 | loss: 0.0169  | val_logits_ll: 0.01738 |  0:01:30s\n",
      "epoch 50 | loss: 0.01648 | val_logits_ll: 0.0186  |  0:01:52s\n",
      "epoch 60 | loss: 0.01622 | val_logits_ll: 0.01766 |  0:02:13s\n",
      "epoch 70 | loss: 0.01604 | val_logits_ll: 0.01735 |  0:02:36s\n",
      "epoch 80 | loss: 0.01587 | val_logits_ll: 0.01666 |  0:02:58s\n",
      "epoch 90 | loss: 0.01572 | val_logits_ll: 0.01678 |  0:03:19s\n",
      "epoch 100| loss: 0.01548 | val_logits_ll: 0.01676 |  0:03:42s\n",
      "epoch 110| loss: 0.01502 | val_logits_ll: 0.01679 |  0:04:03s\n",
      "\n",
      "Early stopping occured at epoch 117 with best_epoch = 97 and best_val_logits_ll = 0.0166\n",
      "Best weights from best epoch are automatically used!\n",
      "\u001b[33m ------------------------------------------------------------\n",
      "Successfully saved model at TabNet_seed_20_fold_3.zip\n",
      "Device used : cuda\n",
      "Device used : cuda\n",
      "Device used : cuda\n",
      "\u001b[34m FOLDS:  \u001b[31m 4 \u001b[33m seed: 20\n",
      "\u001b[32m ************************************************************ \u001b[36m\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.3342  | val_logits_ll: 0.03196 |  0:00:02s\n",
      "epoch 10 | loss: 0.01949 | val_logits_ll: 0.01926 |  0:00:26s\n",
      "epoch 20 | loss: 0.01783 | val_logits_ll: 0.01837 |  0:00:50s\n",
      "epoch 30 | loss: 0.01746 | val_logits_ll: 0.01771 |  0:01:14s\n",
      "epoch 40 | loss: 0.01711 | val_logits_ll: 0.01688 |  0:01:37s\n",
      "epoch 50 | loss: 0.01695 | val_logits_ll: 0.01682 |  0:02:00s\n",
      "epoch 60 | loss: 0.01669 | val_logits_ll: 0.01708 |  0:02:24s\n",
      "epoch 70 | loss: 0.0165  | val_logits_ll: 0.01667 |  0:02:48s\n",
      "epoch 80 | loss: 0.01628 | val_logits_ll: 0.01656 |  0:03:12s\n",
      "epoch 90 | loss: 0.01599 | val_logits_ll: 0.0165  |  0:03:35s\n",
      "epoch 100| loss: 0.0159  | val_logits_ll: 0.01649 |  0:03:58s\n",
      "epoch 110| loss: 0.01563 | val_logits_ll: 0.0165  |  0:04:22s\n",
      "epoch 120| loss: 0.01542 | val_logits_ll: 0.01641 |  0:04:44s\n",
      "epoch 130| loss: 0.01511 | val_logits_ll: 0.01672 |  0:05:07s\n",
      "epoch 140| loss: 0.01476 | val_logits_ll: 0.01664 |  0:05:29s\n",
      "\n",
      "Early stopping occured at epoch 143 with best_epoch = 123 and best_val_logits_ll = 0.01639\n",
      "Best weights from best epoch are automatically used!\n",
      "\u001b[33m ------------------------------------------------------------\n",
      "Successfully saved model at TabNet_seed_20_fold_4.zip\n",
      "Device used : cuda\n",
      "Device used : cuda\n",
      "Device used : cuda\n",
      "\u001b[34m FOLDS:  \u001b[31m 5 \u001b[33m seed: 20\n",
      "\u001b[32m ************************************************************ \u001b[36m\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.33199 | val_logits_ll: 0.03131 |  0:00:02s\n",
      "epoch 10 | loss: 0.01928 | val_logits_ll: 0.0199  |  0:00:23s\n",
      "epoch 20 | loss: 0.01763 | val_logits_ll: 0.02244 |  0:00:46s\n",
      "epoch 30 | loss: 0.01708 | val_logits_ll: 0.01763 |  0:01:08s\n",
      "epoch 40 | loss: 0.01673 | val_logits_ll: 0.01723 |  0:01:30s\n",
      "epoch 50 | loss: 0.01639 | val_logits_ll: 0.01701 |  0:01:52s\n",
      "epoch 60 | loss: 0.01613 | val_logits_ll: 0.01681 |  0:02:14s\n",
      "epoch 70 | loss: 0.01577 | val_logits_ll: 0.01676 |  0:02:37s\n",
      "epoch 80 | loss: 0.01555 | val_logits_ll: 0.01664 |  0:02:58s\n",
      "epoch 90 | loss: 0.01515 | val_logits_ll: 0.01667 |  0:03:20s\n",
      "\n",
      "Early stopping occured at epoch 94 with best_epoch = 74 and best_val_logits_ll = 0.01661\n",
      "Best weights from best epoch are automatically used!\n",
      "\u001b[33m ------------------------------------------------------------\n",
      "Successfully saved model at TabNet_seed_20_fold_5.zip\n",
      "Device used : cuda\n",
      "Device used : cuda\n",
      "Device used : cuda\n",
      "\u001b[34m FOLDS:  \u001b[31m 6 \u001b[33m seed: 20\n",
      "\u001b[32m ************************************************************ \u001b[36m\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.33386 | val_logits_ll: 0.0312  |  0:00:02s\n",
      "epoch 10 | loss: 0.01903 | val_logits_ll: 0.01867 |  0:00:24s\n",
      "epoch 20 | loss: 0.0178  | val_logits_ll: 0.01774 |  0:00:46s\n",
      "epoch 30 | loss: 0.01721 | val_logits_ll: 0.01695 |  0:01:09s\n",
      "epoch 40 | loss: 0.01692 | val_logits_ll: 0.01692 |  0:01:30s\n",
      "epoch 50 | loss: 0.01658 | val_logits_ll: 0.01679 |  0:01:53s\n",
      "epoch 60 | loss: 0.01649 | val_logits_ll: 0.01667 |  0:02:15s\n",
      "epoch 70 | loss: 0.0162  | val_logits_ll: 0.01647 |  0:02:36s\n",
      "epoch 80 | loss: 0.0161  | val_logits_ll: 0.01646 |  0:02:59s\n",
      "epoch 90 | loss: 0.01604 | val_logits_ll: 0.01675 |  0:03:21s\n",
      "epoch 100| loss: 0.01569 | val_logits_ll: 0.01649 |  0:03:42s\n",
      "epoch 110| loss: 0.01538 | val_logits_ll: 0.01637 |  0:04:05s\n",
      "\n",
      "Early stopping occured at epoch 118 with best_epoch = 98 and best_val_logits_ll = 0.01627\n",
      "Best weights from best epoch are automatically used!\n",
      "\u001b[33m ------------------------------------------------------------\n",
      "Successfully saved model at TabNet_seed_20_fold_6.zip\n",
      "Device used : cuda\n",
      "Device used : cuda\n",
      "Device used : cuda\n",
      "\u001b[34m FOLDS:  \u001b[31m 7 \u001b[33m seed: 20\n",
      "\u001b[32m ************************************************************ \u001b[36m\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.3336  | val_logits_ll: 0.03193 |  0:00:02s\n",
      "epoch 10 | loss: 0.01914 | val_logits_ll: 0.01943 |  0:00:23s\n",
      "epoch 20 | loss: 0.01759 | val_logits_ll: 0.02166 |  0:00:46s\n",
      "epoch 30 | loss: 0.01714 | val_logits_ll: 0.01707 |  0:01:08s\n",
      "epoch 40 | loss: 0.01682 | val_logits_ll: 0.01691 |  0:01:29s\n",
      "epoch 50 | loss: 0.01653 | val_logits_ll: 0.01671 |  0:01:52s\n",
      "epoch 60 | loss: 0.01625 | val_logits_ll: 0.01654 |  0:02:14s\n",
      "epoch 70 | loss: 0.01609 | val_logits_ll: 0.0165  |  0:02:36s\n",
      "epoch 80 | loss: 0.01577 | val_logits_ll: 0.01644 |  0:02:57s\n",
      "epoch 90 | loss: 0.01565 | val_logits_ll: 0.01645 |  0:03:19s\n",
      "epoch 100| loss: 0.01557 | val_logits_ll: 0.01644 |  0:03:41s\n",
      "epoch 110| loss: 0.0153  | val_logits_ll: 0.01652 |  0:04:02s\n",
      "epoch 120| loss: 0.01492 | val_logits_ll: 0.01652 |  0:04:24s\n",
      "epoch 130| loss: 0.01453 | val_logits_ll: 0.01679 |  0:04:47s\n",
      "\n",
      "Early stopping occured at epoch 133 with best_epoch = 113 and best_val_logits_ll = 0.01625\n",
      "Best weights from best epoch are automatically used!\n",
      "\u001b[33m ------------------------------------------------------------\n",
      "Successfully saved model at TabNet_seed_20_fold_7.zip\n",
      "Device used : cuda\n",
      "Device used : cuda\n",
      "Device used : cuda\n",
      "\u001b[34m FOLDS:  \u001b[31m 8 \u001b[33m seed: 20\n",
      "\u001b[32m ************************************************************ \u001b[36m\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.33369 | val_logits_ll: 0.0316  |  0:00:02s\n",
      "epoch 10 | loss: 0.01931 | val_logits_ll: 0.01904 |  0:00:23s\n",
      "epoch 20 | loss: 0.01775 | val_logits_ll: 0.02164 |  0:00:46s\n",
      "epoch 30 | loss: 0.01749 | val_logits_ll: 0.01817 |  0:01:08s\n",
      "epoch 40 | loss: 0.01711 | val_logits_ll: 0.01689 |  0:01:30s\n",
      "epoch 50 | loss: 0.01681 | val_logits_ll: 0.01675 |  0:01:52s\n",
      "epoch 60 | loss: 0.01656 | val_logits_ll: 0.01677 |  0:02:14s\n",
      "epoch 70 | loss: 0.01636 | val_logits_ll: 0.01687 |  0:02:37s\n",
      "epoch 80 | loss: 0.01634 | val_logits_ll: 0.01685 |  0:02:59s\n",
      "epoch 90 | loss: 0.01617 | val_logits_ll: 0.01671 |  0:03:21s\n",
      "epoch 100| loss: 0.01599 | val_logits_ll: 0.01662 |  0:03:44s\n",
      "epoch 110| loss: 0.01574 | val_logits_ll: 0.01668 |  0:04:05s\n",
      "epoch 120| loss: 0.01551 | val_logits_ll: 0.01651 |  0:04:27s\n",
      "epoch 130| loss: 0.01532 | val_logits_ll: 0.01672 |  0:04:50s\n",
      "\n",
      "Early stopping occured at epoch 135 with best_epoch = 115 and best_val_logits_ll = 0.01642\n",
      "Best weights from best epoch are automatically used!\n",
      "\u001b[33m ------------------------------------------------------------\n",
      "Successfully saved model at TabNet_seed_20_fold_8.zip\n",
      "Device used : cuda\n",
      "Device used : cuda\n",
      "Device used : cuda\n",
      "\u001b[34m FOLDS:  \u001b[31m 9 \u001b[33m seed: 20\n",
      "\u001b[32m ************************************************************ \u001b[36m\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.33433 | val_logits_ll: 0.03074 |  0:00:02s\n",
      "epoch 10 | loss: 0.0194  | val_logits_ll: 0.01885 |  0:00:24s\n",
      "epoch 20 | loss: 0.01779 | val_logits_ll: 0.01964 |  0:00:47s\n",
      "epoch 30 | loss: 0.01741 | val_logits_ll: 0.01738 |  0:01:09s\n",
      "epoch 40 | loss: 0.01716 | val_logits_ll: 0.01716 |  0:01:32s\n",
      "epoch 50 | loss: 0.01688 | val_logits_ll: 0.01708 |  0:01:54s\n",
      "epoch 60 | loss: 0.01664 | val_logits_ll: 0.01707 |  0:02:16s\n",
      "epoch 70 | loss: 0.01653 | val_logits_ll: 0.01681 |  0:02:39s\n",
      "epoch 80 | loss: 0.01632 | val_logits_ll: 0.01692 |  0:03:00s\n",
      "epoch 90 | loss: 0.01617 | val_logits_ll: 0.01687 |  0:03:22s\n",
      "epoch 100| loss: 0.016   | val_logits_ll: 0.01685 |  0:03:45s\n",
      "epoch 110| loss: 0.0157  | val_logits_ll: 0.01646 |  0:04:07s\n",
      "epoch 120| loss: 0.01556 | val_logits_ll: 0.01653 |  0:04:30s\n",
      "epoch 130| loss: 0.01536 | val_logits_ll: 0.01662 |  0:04:53s\n",
      "epoch 140| loss: 0.01509 | val_logits_ll: 0.01666 |  0:05:15s\n",
      "\n",
      "Early stopping occured at epoch 144 with best_epoch = 124 and best_val_logits_ll = 0.01644\n",
      "Best weights from best epoch are automatically used!\n",
      "\u001b[33m ------------------------------------------------------------\n",
      "Successfully saved model at TabNet_seed_20_fold_9.zip\n",
      "Device used : cuda\n",
      "Device used : cuda\n",
      "Device used : cuda\n",
      "\u001b[34m FOLDS:  \u001b[31m 10 \u001b[33m seed: 20\n",
      "\u001b[32m ************************************************************ \u001b[36m\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.33174 | val_logits_ll: 0.03089 |  0:00:02s\n",
      "epoch 10 | loss: 0.01896 | val_logits_ll: 0.02124 |  0:00:25s\n",
      "epoch 20 | loss: 0.01752 | val_logits_ll: 0.02015 |  0:00:48s\n",
      "epoch 30 | loss: 0.01707 | val_logits_ll: 0.01754 |  0:01:11s\n",
      "epoch 40 | loss: 0.01678 | val_logits_ll: 0.01687 |  0:01:34s\n",
      "epoch 50 | loss: 0.01657 | val_logits_ll: 0.01684 |  0:01:57s\n",
      "epoch 60 | loss: 0.01615 | val_logits_ll: 0.01664 |  0:02:21s\n",
      "epoch 70 | loss: 0.01593 | val_logits_ll: 0.01654 |  0:02:43s\n",
      "epoch 80 | loss: 0.01567 | val_logits_ll: 0.01666 |  0:03:07s\n",
      "epoch 90 | loss: 0.01556 | val_logits_ll: 0.01685 |  0:03:29s\n",
      "epoch 100| loss: 0.01524 | val_logits_ll: 0.0167  |  0:03:51s\n",
      "\n",
      "Early stopping occured at epoch 104 with best_epoch = 84 and best_val_logits_ll = 0.01649\n",
      "Best weights from best epoch are automatically used!\n",
      "\u001b[33m ------------------------------------------------------------\n",
      "Successfully saved model at TabNet_seed_20_fold_10.zip\n",
      "Device used : cuda\n",
      "Device used : cuda\n",
      "Device used : cuda\n",
      "\u001b[34m FOLDS:  \u001b[31m 1 \u001b[33m seed: 21\n",
      "\u001b[32m ************************************************************ \u001b[36m\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.30833 | val_logits_ll: 0.02783 |  0:00:02s\n",
      "epoch 10 | loss: 0.01925 | val_logits_ll: 0.01917 |  0:00:26s\n",
      "epoch 20 | loss: 0.0176  | val_logits_ll: 0.01976 |  0:00:51s\n",
      "epoch 30 | loss: 0.01701 | val_logits_ll: 0.01751 |  0:01:17s\n",
      "epoch 40 | loss: 0.01671 | val_logits_ll: 0.01686 |  0:01:41s\n",
      "epoch 50 | loss: 0.01649 | val_logits_ll: 0.01654 |  0:02:07s\n",
      "epoch 60 | loss: 0.01633 | val_logits_ll: 0.01673 |  0:02:31s\n",
      "epoch 70 | loss: 0.01608 | val_logits_ll: 0.01668 |  0:02:57s\n",
      "\n",
      "Early stopping occured at epoch 79 with best_epoch = 59 and best_val_logits_ll = 0.01647\n",
      "Best weights from best epoch are automatically used!\n",
      "\u001b[33m ------------------------------------------------------------\n",
      "Successfully saved model at TabNet_seed_21_fold_1.zip\n",
      "Device used : cuda\n",
      "Device used : cuda\n",
      "Device used : cuda\n",
      "\u001b[34m FOLDS:  \u001b[31m 2 \u001b[33m seed: 21\n",
      "\u001b[32m ************************************************************ \u001b[36m\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.30787 | val_logits_ll: 0.02821 |  0:00:02s\n",
      "epoch 10 | loss: 0.01911 | val_logits_ll: 0.01909 |  0:00:27s\n",
      "epoch 20 | loss: 0.01771 | val_logits_ll: 0.01933 |  0:00:52s\n",
      "epoch 30 | loss: 0.01717 | val_logits_ll: 0.01985 |  0:01:17s\n",
      "epoch 40 | loss: 0.01692 | val_logits_ll: 0.01695 |  0:01:43s\n",
      "epoch 50 | loss: 0.0167  | val_logits_ll: 0.01686 |  0:02:07s\n",
      "epoch 60 | loss: 0.01641 | val_logits_ll: 0.01673 |  0:02:32s\n",
      "epoch 70 | loss: 0.01626 | val_logits_ll: 0.0168  |  0:02:57s\n",
      "epoch 80 | loss: 0.01587 | val_logits_ll: 0.01651 |  0:03:22s\n",
      "epoch 90 | loss: 0.0156  | val_logits_ll: 0.01651 |  0:03:48s\n",
      "epoch 100| loss: 0.01532 | val_logits_ll: 0.01678 |  0:04:13s\n",
      "\n",
      "Early stopping occured at epoch 101 with best_epoch = 81 and best_val_logits_ll = 0.01639\n",
      "Best weights from best epoch are automatically used!\n",
      "\u001b[33m ------------------------------------------------------------\n",
      "Successfully saved model at TabNet_seed_21_fold_2.zip\n",
      "Device used : cuda\n",
      "Device used : cuda\n",
      "Device used : cuda\n",
      "\u001b[34m FOLDS:  \u001b[31m 3 \u001b[33m seed: 21\n",
      "\u001b[32m ************************************************************ \u001b[36m\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.31088 | val_logits_ll: 0.02961 |  0:00:02s\n",
      "epoch 10 | loss: 0.01956 | val_logits_ll: 0.01942 |  0:00:24s\n",
      "epoch 20 | loss: 0.01793 | val_logits_ll: 0.02009 |  0:00:46s\n",
      "epoch 30 | loss: 0.01723 | val_logits_ll: 0.01755 |  0:01:08s\n",
      "epoch 40 | loss: 0.01696 | val_logits_ll: 0.01759 |  0:01:31s\n",
      "epoch 50 | loss: 0.0169  | val_logits_ll: 0.01753 |  0:01:52s\n",
      "epoch 60 | loss: 0.01647 | val_logits_ll: 0.017   |  0:02:15s\n",
      "epoch 70 | loss: 0.01632 | val_logits_ll: 0.01683 |  0:02:37s\n",
      "epoch 80 | loss: 0.016   | val_logits_ll: 0.01675 |  0:02:59s\n",
      "epoch 90 | loss: 0.01575 | val_logits_ll: 0.01674 |  0:03:22s\n",
      "epoch 100| loss: 0.01548 | val_logits_ll: 0.01681 |  0:03:43s\n",
      "epoch 110| loss: 0.0151  | val_logits_ll: 0.01689 |  0:04:05s\n",
      "epoch 120| loss: 0.01479 | val_logits_ll: 0.01686 |  0:04:28s\n",
      "epoch 130| loss: 0.01441 | val_logits_ll: 0.01707 |  0:04:49s\n",
      "\n",
      "Early stopping occured at epoch 137 with best_epoch = 117 and best_val_logits_ll = 0.01659\n",
      "Best weights from best epoch are automatically used!\n",
      "\u001b[33m ------------------------------------------------------------\n",
      "Successfully saved model at TabNet_seed_21_fold_3.zip\n",
      "Device used : cuda\n",
      "Device used : cuda\n",
      "Device used : cuda\n",
      "\u001b[34m FOLDS:  \u001b[31m 4 \u001b[33m seed: 21\n",
      "\u001b[32m ************************************************************ \u001b[36m\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.31183 | val_logits_ll: 0.02996 |  0:00:02s\n",
      "epoch 10 | loss: 0.01961 | val_logits_ll: 0.01902 |  0:00:25s\n",
      "epoch 20 | loss: 0.01765 | val_logits_ll: 0.01843 |  0:00:47s\n",
      "epoch 30 | loss: 0.01729 | val_logits_ll: 0.0176  |  0:01:09s\n",
      "epoch 40 | loss: 0.01696 | val_logits_ll: 0.01674 |  0:01:32s\n",
      "epoch 50 | loss: 0.0167  | val_logits_ll: 0.01669 |  0:01:53s\n",
      "epoch 60 | loss: 0.01649 | val_logits_ll: 0.01663 |  0:02:17s\n",
      "epoch 70 | loss: 0.01621 | val_logits_ll: 0.01658 |  0:02:39s\n",
      "epoch 80 | loss: 0.01586 | val_logits_ll: 0.01652 |  0:03:01s\n",
      "epoch 90 | loss: 0.0157  | val_logits_ll: 0.01646 |  0:03:24s\n",
      "epoch 100| loss: 0.01523 | val_logits_ll: 0.01638 |  0:03:46s\n",
      "\n",
      "Early stopping occured at epoch 106 with best_epoch = 86 and best_val_logits_ll = 0.01637\n",
      "Best weights from best epoch are automatically used!\n",
      "\u001b[33m ------------------------------------------------------------\n",
      "Successfully saved model at TabNet_seed_21_fold_4.zip\n",
      "Device used : cuda\n",
      "Device used : cuda\n",
      "Device used : cuda\n",
      "\u001b[34m FOLDS:  \u001b[31m 5 \u001b[33m seed: 21\n",
      "\u001b[32m ************************************************************ \u001b[36m\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.30894 | val_logits_ll: 0.02909 |  0:00:02s\n",
      "epoch 10 | loss: 0.01928 | val_logits_ll: 0.01942 |  0:00:25s\n",
      "epoch 20 | loss: 0.0179  | val_logits_ll: 0.01796 |  0:00:47s\n",
      "epoch 30 | loss: 0.01759 | val_logits_ll: 0.01749 |  0:01:09s\n",
      "epoch 40 | loss: 0.01714 | val_logits_ll: 0.01723 |  0:01:32s\n",
      "epoch 50 | loss: 0.01703 | val_logits_ll: 0.01712 |  0:01:54s\n",
      "epoch 60 | loss: 0.01669 | val_logits_ll: 0.01694 |  0:02:17s\n",
      "epoch 70 | loss: 0.01648 | val_logits_ll: 0.0168  |  0:02:39s\n",
      "epoch 80 | loss: 0.01654 | val_logits_ll: 0.01671 |  0:03:01s\n",
      "epoch 90 | loss: 0.01629 | val_logits_ll: 0.01688 |  0:03:23s\n",
      "epoch 100| loss: 0.01606 | val_logits_ll: 0.01668 |  0:03:46s\n",
      "epoch 110| loss: 0.01592 | val_logits_ll: 0.01674 |  0:04:08s\n",
      "epoch 120| loss: 0.01565 | val_logits_ll: 0.01661 |  0:04:30s\n",
      "epoch 130| loss: 0.01548 | val_logits_ll: 0.0167  |  0:04:52s\n",
      "\n",
      "Early stopping occured at epoch 133 with best_epoch = 113 and best_val_logits_ll = 0.01657\n",
      "Best weights from best epoch are automatically used!\n",
      "\u001b[33m ------------------------------------------------------------\n",
      "Successfully saved model at TabNet_seed_21_fold_5.zip\n",
      "Device used : cuda\n",
      "Device used : cuda\n",
      "Device used : cuda\n",
      "\u001b[34m FOLDS:  \u001b[31m 6 \u001b[33m seed: 21\n",
      "\u001b[32m ************************************************************ \u001b[36m\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.31195 | val_logits_ll: 0.02986 |  0:00:02s\n",
      "epoch 10 | loss: 0.01907 | val_logits_ll: 0.01878 |  0:00:25s\n",
      "epoch 20 | loss: 0.01745 | val_logits_ll: 0.02013 |  0:00:47s\n",
      "epoch 30 | loss: 0.01694 | val_logits_ll: 0.01713 |  0:01:08s\n",
      "epoch 40 | loss: 0.01659 | val_logits_ll: 0.01665 |  0:01:31s\n",
      "epoch 50 | loss: 0.01646 | val_logits_ll: 0.0167  |  0:01:53s\n",
      "epoch 60 | loss: 0.01638 | val_logits_ll: 0.01648 |  0:02:16s\n",
      "epoch 70 | loss: 0.01602 | val_logits_ll: 0.01658 |  0:02:37s\n",
      "epoch 80 | loss: 0.01583 | val_logits_ll: 0.01636 |  0:02:59s\n",
      "epoch 90 | loss: 0.01549 | val_logits_ll: 0.01633 |  0:03:22s\n",
      "epoch 100| loss: 0.01526 | val_logits_ll: 0.01642 |  0:03:43s\n",
      "epoch 110| loss: 0.01501 | val_logits_ll: 0.01636 |  0:04:06s\n",
      "\n",
      "Early stopping occured at epoch 111 with best_epoch = 91 and best_val_logits_ll = 0.01617\n",
      "Best weights from best epoch are automatically used!\n",
      "\u001b[33m ------------------------------------------------------------\n",
      "Successfully saved model at TabNet_seed_21_fold_6.zip\n",
      "Device used : cuda\n",
      "Device used : cuda\n",
      "Device used : cuda\n",
      "\u001b[34m FOLDS:  \u001b[31m 7 \u001b[33m seed: 21\n",
      "\u001b[32m ************************************************************ \u001b[36m\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.30934 | val_logits_ll: 0.02915 |  0:00:02s\n",
      "epoch 10 | loss: 0.01927 | val_logits_ll: 0.02004 |  0:00:24s\n",
      "epoch 20 | loss: 0.01775 | val_logits_ll: 0.01989 |  0:00:45s\n",
      "epoch 30 | loss: 0.01717 | val_logits_ll: 0.01731 |  0:01:08s\n",
      "epoch 40 | loss: 0.01678 | val_logits_ll: 0.01681 |  0:01:30s\n",
      "epoch 50 | loss: 0.01667 | val_logits_ll: 0.0172  |  0:01:51s\n",
      "epoch 60 | loss: 0.01628 | val_logits_ll: 0.0167  |  0:02:14s\n",
      "epoch 70 | loss: 0.01611 | val_logits_ll: 0.01658 |  0:02:35s\n",
      "epoch 80 | loss: 0.01604 | val_logits_ll: 0.01658 |  0:02:57s\n",
      "epoch 90 | loss: 0.01573 | val_logits_ll: 0.01657 |  0:03:20s\n",
      "epoch 100| loss: 0.01564 | val_logits_ll: 0.01652 |  0:03:41s\n",
      "\n",
      "Early stopping occured at epoch 103 with best_epoch = 83 and best_val_logits_ll = 0.01639\n",
      "Best weights from best epoch are automatically used!\n",
      "\u001b[33m ------------------------------------------------------------\n",
      "Successfully saved model at TabNet_seed_21_fold_7.zip\n",
      "Device used : cuda\n",
      "Device used : cuda\n",
      "Device used : cuda\n",
      "\u001b[34m FOLDS:  \u001b[31m 8 \u001b[33m seed: 21\n",
      "\u001b[32m ************************************************************ \u001b[36m\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.31032 | val_logits_ll: 0.0302  |  0:00:02s\n",
      "epoch 10 | loss: 0.01982 | val_logits_ll: 0.02061 |  0:00:24s\n",
      "epoch 20 | loss: 0.01793 | val_logits_ll: 0.01808 |  0:00:46s\n",
      "epoch 30 | loss: 0.01746 | val_logits_ll: 0.01735 |  0:01:08s\n",
      "epoch 40 | loss: 0.01715 | val_logits_ll: 0.0172  |  0:01:30s\n",
      "epoch 50 | loss: 0.01685 | val_logits_ll: 0.01702 |  0:01:51s\n",
      "epoch 60 | loss: 0.01658 | val_logits_ll: 0.01699 |  0:02:14s\n",
      "epoch 70 | loss: 0.01642 | val_logits_ll: 0.01671 |  0:02:36s\n",
      "epoch 80 | loss: 0.01616 | val_logits_ll: 0.01664 |  0:02:57s\n",
      "epoch 90 | loss: 0.01602 | val_logits_ll: 0.01654 |  0:03:20s\n",
      "epoch 100| loss: 0.01574 | val_logits_ll: 0.0166  |  0:03:42s\n",
      "epoch 110| loss: 0.0154  | val_logits_ll: 0.01673 |  0:04:03s\n",
      "\n",
      "Early stopping occured at epoch 110 with best_epoch = 90 and best_val_logits_ll = 0.01654\n",
      "Best weights from best epoch are automatically used!\n",
      "\u001b[33m ------------------------------------------------------------\n",
      "Successfully saved model at TabNet_seed_21_fold_8.zip\n",
      "Device used : cuda\n",
      "Device used : cuda\n",
      "Device used : cuda\n",
      "\u001b[34m FOLDS:  \u001b[31m 9 \u001b[33m seed: 21\n",
      "\u001b[32m ************************************************************ \u001b[36m\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.30543 | val_logits_ll: 0.02787 |  0:00:02s\n",
      "epoch 10 | loss: 0.01904 | val_logits_ll: 0.0209  |  0:00:25s\n",
      "epoch 20 | loss: 0.01773 | val_logits_ll: 0.01781 |  0:00:46s\n",
      "epoch 30 | loss: 0.01722 | val_logits_ll: 0.01724 |  0:01:09s\n",
      "epoch 40 | loss: 0.01688 | val_logits_ll: 0.01723 |  0:01:31s\n",
      "epoch 50 | loss: 0.01674 | val_logits_ll: 0.01761 |  0:01:53s\n",
      "epoch 60 | loss: 0.01642 | val_logits_ll: 0.01674 |  0:02:17s\n",
      "epoch 70 | loss: 0.01626 | val_logits_ll: 0.01689 |  0:02:39s\n",
      "epoch 80 | loss: 0.01599 | val_logits_ll: 0.01663 |  0:03:04s\n",
      "epoch 90 | loss: 0.01585 | val_logits_ll: 0.01668 |  0:03:26s\n",
      "epoch 100| loss: 0.01562 | val_logits_ll: 0.0167  |  0:03:47s\n",
      "epoch 110| loss: 0.01537 | val_logits_ll: 0.01663 |  0:04:09s\n",
      "epoch 120| loss: 0.01503 | val_logits_ll: 0.01665 |  0:04:31s\n",
      "\n",
      "Early stopping occured at epoch 125 with best_epoch = 105 and best_val_logits_ll = 0.01651\n",
      "Best weights from best epoch are automatically used!\n",
      "\u001b[33m ------------------------------------------------------------\n",
      "Successfully saved model at TabNet_seed_21_fold_9.zip\n",
      "Device used : cuda\n",
      "Device used : cuda\n",
      "Device used : cuda\n",
      "\u001b[34m FOLDS:  \u001b[31m 10 \u001b[33m seed: 21\n",
      "\u001b[32m ************************************************************ \u001b[36m\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.30888 | val_logits_ll: 0.0287  |  0:00:02s\n",
      "epoch 10 | loss: 0.01901 | val_logits_ll: 0.01894 |  0:00:24s\n",
      "epoch 20 | loss: 0.01763 | val_logits_ll: 0.01767 |  0:00:46s\n",
      "epoch 30 | loss: 0.01725 | val_logits_ll: 0.01945 |  0:01:07s\n",
      "epoch 40 | loss: 0.01682 | val_logits_ll: 0.01685 |  0:01:30s\n",
      "epoch 50 | loss: 0.01659 | val_logits_ll: 0.01681 |  0:01:51s\n",
      "epoch 60 | loss: 0.01614 | val_logits_ll: 0.01695 |  0:02:13s\n",
      "epoch 70 | loss: 0.01599 | val_logits_ll: 0.01678 |  0:02:36s\n",
      "epoch 80 | loss: 0.01563 | val_logits_ll: 0.01654 |  0:02:57s\n",
      "epoch 90 | loss: 0.01551 | val_logits_ll: 0.01655 |  0:03:19s\n",
      "epoch 100| loss: 0.01514 | val_logits_ll: 0.01671 |  0:03:41s\n",
      "\n",
      "Early stopping occured at epoch 105 with best_epoch = 85 and best_val_logits_ll = 0.01649\n",
      "Best weights from best epoch are automatically used!\n",
      "\u001b[33m ------------------------------------------------------------\n",
      "Successfully saved model at TabNet_seed_21_fold_10.zip\n",
      "Device used : cuda\n",
      "Device used : cuda\n",
      "Device used : cuda\n",
      "\u001b[34m FOLDS:  \u001b[31m 1 \u001b[33m seed: 22\n",
      "\u001b[32m ************************************************************ \u001b[36m\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.30051 | val_logits_ll: 0.02892 |  0:00:02s\n",
      "epoch 10 | loss: 0.01872 | val_logits_ll: 0.02027 |  0:00:24s\n",
      "epoch 20 | loss: 0.01756 | val_logits_ll: 0.02047 |  0:00:45s\n",
      "epoch 30 | loss: 0.01698 | val_logits_ll: 0.01786 |  0:01:07s\n",
      "epoch 40 | loss: 0.01685 | val_logits_ll: 0.01683 |  0:01:29s\n",
      "epoch 50 | loss: 0.01663 | val_logits_ll: 0.01676 |  0:01:51s\n",
      "epoch 60 | loss: 0.0163  | val_logits_ll: 0.01684 |  0:02:12s\n",
      "epoch 70 | loss: 0.01612 | val_logits_ll: 0.01671 |  0:02:35s\n",
      "epoch 80 | loss: 0.01601 | val_logits_ll: 0.0167  |  0:02:57s\n",
      "epoch 90 | loss: 0.01565 | val_logits_ll: 0.01659 |  0:03:18s\n",
      "epoch 100| loss: 0.01529 | val_logits_ll: 0.01672 |  0:03:41s\n",
      "epoch 110| loss: 0.01518 | val_logits_ll: 0.01665 |  0:04:03s\n",
      "\n",
      "Early stopping occured at epoch 112 with best_epoch = 92 and best_val_logits_ll = 0.01653\n",
      "Best weights from best epoch are automatically used!\n",
      "\u001b[33m ------------------------------------------------------------\n",
      "Successfully saved model at TabNet_seed_22_fold_1.zip\n",
      "Device used : cuda\n",
      "Device used : cuda\n",
      "Device used : cuda\n",
      "\u001b[34m FOLDS:  \u001b[31m 2 \u001b[33m seed: 22\n",
      "\u001b[32m ************************************************************ \u001b[36m\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.29885 | val_logits_ll: 0.02923 |  0:00:02s\n",
      "epoch 10 | loss: 0.01878 | val_logits_ll: 0.01859 |  0:00:24s\n",
      "epoch 20 | loss: 0.01759 | val_logits_ll: 0.02026 |  0:00:45s\n",
      "epoch 30 | loss: 0.01694 | val_logits_ll: 0.01711 |  0:01:07s\n",
      "epoch 40 | loss: 0.01678 | val_logits_ll: 0.01702 |  0:01:29s\n",
      "epoch 50 | loss: 0.01669 | val_logits_ll: 0.01689 |  0:01:51s\n",
      "epoch 60 | loss: 0.01634 | val_logits_ll: 0.01713 |  0:02:13s\n",
      "epoch 70 | loss: 0.01627 | val_logits_ll: 0.0166  |  0:02:35s\n",
      "epoch 80 | loss: 0.01597 | val_logits_ll: 0.01658 |  0:02:56s\n",
      "epoch 90 | loss: 0.01589 | val_logits_ll: 0.01648 |  0:03:19s\n",
      "epoch 100| loss: 0.01562 | val_logits_ll: 0.01657 |  0:03:40s\n",
      "\n",
      "Early stopping occured at epoch 106 with best_epoch = 86 and best_val_logits_ll = 0.01648\n",
      "Best weights from best epoch are automatically used!\n",
      "\u001b[33m ------------------------------------------------------------\n",
      "Successfully saved model at TabNet_seed_22_fold_2.zip\n",
      "Device used : cuda\n",
      "Device used : cuda\n",
      "Device used : cuda\n",
      "\u001b[34m FOLDS:  \u001b[31m 3 \u001b[33m seed: 22\n",
      "\u001b[32m ************************************************************ \u001b[36m\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.2994  | val_logits_ll: 0.02904 |  0:00:02s\n",
      "epoch 10 | loss: 0.01876 | val_logits_ll: 0.02011 |  0:00:24s\n",
      "epoch 20 | loss: 0.0177  | val_logits_ll: 0.01944 |  0:00:45s\n",
      "epoch 30 | loss: 0.01724 | val_logits_ll: 0.01984 |  0:01:06s\n",
      "epoch 40 | loss: 0.01687 | val_logits_ll: 0.01719 |  0:01:29s\n",
      "epoch 50 | loss: 0.01658 | val_logits_ll: 0.01693 |  0:01:51s\n",
      "epoch 60 | loss: 0.0164  | val_logits_ll: 0.0168  |  0:02:13s\n",
      "epoch 70 | loss: 0.01617 | val_logits_ll: 0.01672 |  0:02:35s\n",
      "epoch 80 | loss: 0.01593 | val_logits_ll: 0.01701 |  0:02:57s\n",
      "epoch 90 | loss: 0.01575 | val_logits_ll: 0.0167  |  0:03:20s\n",
      "epoch 100| loss: 0.01553 | val_logits_ll: 0.01651 |  0:03:41s\n",
      "epoch 110| loss: 0.01528 | val_logits_ll: 0.01671 |  0:04:03s\n",
      "epoch 120| loss: 0.01483 | val_logits_ll: 0.01661 |  0:04:25s\n",
      "\n",
      "Early stopping occured at epoch 120 with best_epoch = 100 and best_val_logits_ll = 0.01651\n",
      "Best weights from best epoch are automatically used!\n",
      "\u001b[33m ------------------------------------------------------------\n",
      "Successfully saved model at TabNet_seed_22_fold_3.zip\n",
      "Device used : cuda\n",
      "Device used : cuda\n",
      "Device used : cuda\n",
      "\u001b[34m FOLDS:  \u001b[31m 4 \u001b[33m seed: 22\n",
      "\u001b[32m ************************************************************ \u001b[36m\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.29767 | val_logits_ll: 0.02931 |  0:00:02s\n",
      "epoch 10 | loss: 0.01913 | val_logits_ll: 0.02023 |  0:00:23s\n",
      "epoch 20 | loss: 0.01758 | val_logits_ll: 0.01929 |  0:00:44s\n",
      "epoch 30 | loss: 0.01699 | val_logits_ll: 0.01776 |  0:01:07s\n",
      "epoch 40 | loss: 0.0167  | val_logits_ll: 0.0166  |  0:01:28s\n",
      "epoch 50 | loss: 0.01639 | val_logits_ll: 0.01714 |  0:01:50s\n",
      "epoch 60 | loss: 0.01614 | val_logits_ll: 0.01661 |  0:02:12s\n",
      "epoch 70 | loss: 0.01598 | val_logits_ll: 0.0165  |  0:02:33s\n",
      "epoch 80 | loss: 0.01555 | val_logits_ll: 0.01661 |  0:02:56s\n",
      "epoch 90 | loss: 0.01525 | val_logits_ll: 0.01646 |  0:03:18s\n",
      "\n",
      "Early stopping occured at epoch 93 with best_epoch = 73 and best_val_logits_ll = 0.01642\n",
      "Best weights from best epoch are automatically used!\n",
      "\u001b[33m ------------------------------------------------------------\n",
      "Successfully saved model at TabNet_seed_22_fold_4.zip\n",
      "Device used : cuda\n",
      "Device used : cuda\n",
      "Device used : cuda\n",
      "\u001b[34m FOLDS:  \u001b[31m 5 \u001b[33m seed: 22\n",
      "\u001b[32m ************************************************************ \u001b[36m\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.2988  | val_logits_ll: 0.02963 |  0:00:02s\n",
      "epoch 10 | loss: 0.01878 | val_logits_ll: 0.02004 |  0:00:24s\n",
      "epoch 20 | loss: 0.01755 | val_logits_ll: 0.02075 |  0:00:45s\n",
      "epoch 30 | loss: 0.01717 | val_logits_ll: 0.01737 |  0:01:07s\n",
      "epoch 40 | loss: 0.01693 | val_logits_ll: 0.01716 |  0:01:29s\n",
      "epoch 50 | loss: 0.01667 | val_logits_ll: 0.01707 |  0:01:51s\n",
      "epoch 60 | loss: 0.01653 | val_logits_ll: 0.01696 |  0:02:12s\n",
      "epoch 70 | loss: 0.0161  | val_logits_ll: 0.0169  |  0:02:35s\n",
      "epoch 80 | loss: 0.01598 | val_logits_ll: 0.01668 |  0:02:56s\n",
      "\n",
      "Early stopping occured at epoch 89 with best_epoch = 69 and best_val_logits_ll = 0.01658\n",
      "Best weights from best epoch are automatically used!\n",
      "\u001b[33m ------------------------------------------------------------\n",
      "Successfully saved model at TabNet_seed_22_fold_5.zip\n",
      "Device used : cuda\n",
      "Device used : cuda\n",
      "Device used : cuda\n",
      "\u001b[34m FOLDS:  \u001b[31m 6 \u001b[33m seed: 22\n",
      "\u001b[32m ************************************************************ \u001b[36m\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.30208 | val_logits_ll: 0.03052 |  0:00:02s\n",
      "epoch 10 | loss: 0.01904 | val_logits_ll: 0.01906 |  0:00:24s\n",
      "epoch 20 | loss: 0.01772 | val_logits_ll: 0.01865 |  0:00:46s\n",
      "epoch 30 | loss: 0.01716 | val_logits_ll: 0.01708 |  0:01:08s\n",
      "epoch 40 | loss: 0.01685 | val_logits_ll: 0.01678 |  0:01:29s\n",
      "epoch 50 | loss: 0.0166  | val_logits_ll: 0.01718 |  0:01:51s\n",
      "epoch 60 | loss: 0.0164  | val_logits_ll: 0.01651 |  0:02:13s\n",
      "epoch 70 | loss: 0.01629 | val_logits_ll: 0.01659 |  0:02:34s\n",
      "epoch 80 | loss: 0.01629 | val_logits_ll: 0.01642 |  0:02:56s\n",
      "epoch 90 | loss: 0.016   | val_logits_ll: 0.01632 |  0:03:18s\n",
      "epoch 100| loss: 0.01582 | val_logits_ll: 0.01639 |  0:03:39s\n",
      "epoch 110| loss: 0.01552 | val_logits_ll: 0.01627 |  0:04:01s\n",
      "\n",
      "Early stopping occured at epoch 118 with best_epoch = 98 and best_val_logits_ll = 0.01609\n",
      "Best weights from best epoch are automatically used!\n",
      "\u001b[33m ------------------------------------------------------------\n",
      "Successfully saved model at TabNet_seed_22_fold_6.zip\n",
      "Device used : cuda\n",
      "Device used : cuda\n",
      "Device used : cuda\n",
      "\u001b[34m FOLDS:  \u001b[31m 7 \u001b[33m seed: 22\n",
      "\u001b[32m ************************************************************ \u001b[36m\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.29773 | val_logits_ll: 0.02849 |  0:00:02s\n",
      "epoch 10 | loss: 0.01905 | val_logits_ll: 0.02055 |  0:00:23s\n",
      "epoch 20 | loss: 0.01761 | val_logits_ll: 0.02072 |  0:00:45s\n",
      "epoch 30 | loss: 0.01706 | val_logits_ll: 0.01748 |  0:01:07s\n",
      "epoch 40 | loss: 0.01672 | val_logits_ll: 0.01687 |  0:01:28s\n",
      "epoch 50 | loss: 0.01648 | val_logits_ll: 0.01685 |  0:01:51s\n",
      "epoch 60 | loss: 0.01634 | val_logits_ll: 0.01658 |  0:02:12s\n",
      "epoch 70 | loss: 0.01596 | val_logits_ll: 0.0164  |  0:02:33s\n",
      "epoch 80 | loss: 0.01601 | val_logits_ll: 0.01645 |  0:02:55s\n",
      "epoch 90 | loss: 0.01541 | val_logits_ll: 0.01636 |  0:03:16s\n",
      "epoch 100| loss: 0.01517 | val_logits_ll: 0.01662 |  0:03:38s\n",
      "\n",
      "Early stopping occured at epoch 109 with best_epoch = 89 and best_val_logits_ll = 0.01629\n",
      "Best weights from best epoch are automatically used!\n",
      "\u001b[33m ------------------------------------------------------------\n",
      "Successfully saved model at TabNet_seed_22_fold_7.zip\n",
      "Device used : cuda\n",
      "Device used : cuda\n",
      "Device used : cuda\n",
      "\u001b[34m FOLDS:  \u001b[31m 8 \u001b[33m seed: 22\n",
      "\u001b[32m ************************************************************ \u001b[36m\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.29926 | val_logits_ll: 0.02924 |  0:00:02s\n",
      "epoch 10 | loss: 0.01906 | val_logits_ll: 0.01975 |  0:00:24s\n",
      "epoch 20 | loss: 0.0175  | val_logits_ll: 0.02295 |  0:00:46s\n",
      "epoch 30 | loss: 0.01711 | val_logits_ll: 0.01775 |  0:01:09s\n",
      "epoch 40 | loss: 0.01682 | val_logits_ll: 0.01717 |  0:01:30s\n",
      "epoch 50 | loss: 0.01654 | val_logits_ll: 0.01671 |  0:01:53s\n",
      "epoch 60 | loss: 0.01629 | val_logits_ll: 0.01662 |  0:02:15s\n",
      "epoch 70 | loss: 0.01616 | val_logits_ll: 0.01664 |  0:02:37s\n",
      "epoch 80 | loss: 0.01588 | val_logits_ll: 0.01676 |  0:03:00s\n",
      "epoch 90 | loss: 0.01554 | val_logits_ll: 0.01649 |  0:03:22s\n",
      "epoch 100| loss: 0.01524 | val_logits_ll: 0.01658 |  0:03:44s\n",
      "epoch 110| loss: 0.01508 | val_logits_ll: 0.01658 |  0:04:07s\n",
      "epoch 120| loss: 0.01466 | val_logits_ll: 0.01668 |  0:04:28s\n",
      "\n",
      "Early stopping occured at epoch 127 with best_epoch = 107 and best_val_logits_ll = 0.01642\n",
      "Best weights from best epoch are automatically used!\n",
      "\u001b[33m ------------------------------------------------------------\n",
      "Successfully saved model at TabNet_seed_22_fold_8.zip\n",
      "Device used : cuda\n",
      "Device used : cuda\n",
      "Device used : cuda\n",
      "\u001b[34m FOLDS:  \u001b[31m 9 \u001b[33m seed: 22\n",
      "\u001b[32m ************************************************************ \u001b[36m\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.29813 | val_logits_ll: 0.02911 |  0:00:02s\n",
      "epoch 10 | loss: 0.01888 | val_logits_ll: 0.01854 |  0:00:24s\n",
      "epoch 20 | loss: 0.01761 | val_logits_ll: 0.01931 |  0:00:46s\n",
      "epoch 30 | loss: 0.01716 | val_logits_ll: 0.01834 |  0:01:08s\n",
      "epoch 40 | loss: 0.01679 | val_logits_ll: 0.01712 |  0:01:30s\n",
      "epoch 50 | loss: 0.01648 | val_logits_ll: 0.01679 |  0:01:52s\n",
      "epoch 60 | loss: 0.01641 | val_logits_ll: 0.01689 |  0:02:14s\n",
      "epoch 70 | loss: 0.01654 | val_logits_ll: 0.0167  |  0:02:36s\n",
      "epoch 80 | loss: 0.01614 | val_logits_ll: 0.01669 |  0:02:59s\n",
      "epoch 90 | loss: 0.01608 | val_logits_ll: 0.01755 |  0:03:20s\n",
      "epoch 100| loss: 0.01572 | val_logits_ll: 0.0164  |  0:03:42s\n",
      "epoch 110| loss: 0.01553 | val_logits_ll: 0.01647 |  0:04:04s\n",
      "epoch 120| loss: 0.01519 | val_logits_ll: 0.01654 |  0:04:26s\n",
      "\n",
      "Early stopping occured at epoch 120 with best_epoch = 100 and best_val_logits_ll = 0.0164\n",
      "Best weights from best epoch are automatically used!\n",
      "\u001b[33m ------------------------------------------------------------\n",
      "Successfully saved model at TabNet_seed_22_fold_9.zip\n",
      "Device used : cuda\n",
      "Device used : cuda\n",
      "Device used : cuda\n",
      "\u001b[34m FOLDS:  \u001b[31m 10 \u001b[33m seed: 22\n",
      "\u001b[32m ************************************************************ \u001b[36m\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.29922 | val_logits_ll: 0.02888 |  0:00:02s\n",
      "epoch 10 | loss: 0.01898 | val_logits_ll: 0.01863 |  0:00:25s\n",
      "epoch 20 | loss: 0.01767 | val_logits_ll: 0.02101 |  0:00:48s\n",
      "epoch 30 | loss: 0.01716 | val_logits_ll: 0.01717 |  0:01:10s\n",
      "epoch 40 | loss: 0.01693 | val_logits_ll: 0.01705 |  0:01:34s\n",
      "epoch 50 | loss: 0.01676 | val_logits_ll: 0.01678 |  0:01:56s\n",
      "epoch 60 | loss: 0.01659 | val_logits_ll: 0.01676 |  0:02:19s\n",
      "epoch 70 | loss: 0.01629 | val_logits_ll: 0.0167  |  0:02:43s\n",
      "epoch 80 | loss: 0.01611 | val_logits_ll: 0.01663 |  0:03:06s\n",
      "epoch 90 | loss: 0.01594 | val_logits_ll: 0.01648 |  0:03:29s\n",
      "epoch 100| loss: 0.0159  | val_logits_ll: 0.01677 |  0:03:53s\n",
      "epoch 110| loss: 0.01559 | val_logits_ll: 0.01685 |  0:04:15s\n",
      "epoch 120| loss: 0.01535 | val_logits_ll: 0.01646 |  0:04:39s\n",
      "epoch 130| loss: 0.01511 | val_logits_ll: 0.01649 |  0:05:01s\n",
      "epoch 140| loss: 0.01493 | val_logits_ll: 0.01665 |  0:05:24s\n",
      "\n",
      "Early stopping occured at epoch 148 with best_epoch = 128 and best_val_logits_ll = 0.01637\n",
      "Best weights from best epoch are automatically used!\n",
      "\u001b[33m ------------------------------------------------------------\n",
      "Successfully saved model at TabNet_seed_22_fold_10.zip\n",
      "Device used : cuda\n",
      "Device used : cuda\n",
      "Device used : cuda\n"
     ]
    }
   ],
   "source": [
    "scores_auc_all = []\n",
    "test_cv_preds = []\n",
    "\n",
    "NB_SPLITS = 10\n",
    "mskf = MultilabelStratifiedKFold(n_splits = NB_SPLITS, random_state = 0, shuffle = True)\n",
    "\n",
    "oof_preds = []\n",
    "oof_targets = []\n",
    "scores = []\n",
    "scores_auc = []\n",
    "SEED = [20,21,22]\n",
    "for s in SEED:\n",
    "    tabnet_params['seed'] = s\n",
    "    for fold_nb, (train_idx, val_idx) in enumerate(mskf.split(train, target)):\n",
    "        print(b_,\"FOLDS: \", r_, fold_nb + 1, y_, 'seed:', tabnet_params['seed'])\n",
    "        print(g_, '*' * 60, c_)\n",
    "    \n",
    "        X_train, y_train = train.values[train_idx, :], target.values[train_idx, :]\n",
    "        X_val, y_val = train.values[val_idx, :], target.values[val_idx, :]\n",
    "        ### Model ###\n",
    "        model = TabNetRegressor(**tabnet_params)\n",
    "        \n",
    "        ### Fit ###\n",
    "        model.fit(\n",
    "            X_train = X_train,\n",
    "            y_train = y_train,\n",
    "            eval_set = [(X_val, y_val)],\n",
    "            eval_name = [\"val\"],\n",
    "            eval_metric = [\"logits_ll\"],\n",
    "            max_epochs = MAX_EPOCH,\n",
    "            patience = 20,\n",
    "            batch_size = 1024, \n",
    "            virtual_batch_size = 32,\n",
    "            num_workers = 1,\n",
    "            drop_last = False,\n",
    "            loss_fn = SmoothBCEwLogits(smoothing=5e-5))\n",
    "        print(y_, '-' * 60)\n",
    "    \n",
    "        ### Predict on validation ###\n",
    "        preds_val = model.predict(X_val)\n",
    "        # Apply sigmoid to the predictions\n",
    "        preds = 1 / (1 + np.exp(-preds_val))\n",
    "        score = np.min(model.history[\"val_logits_ll\"])\n",
    "        saving_path_name = 'TabNet_seed_'+str(tabnet_params['seed'])+'_fold_'+str(fold_nb+1)\n",
    "        saved_filepath = model.save_model(saving_path_name)\n",
    "        \n",
    "        loaded_model =  TabNetRegressor()\n",
    "        loaded_model.load_model(saved_filepath)\n",
    "    \n",
    "        ### Save OOF for CV ###\n",
    "        oof_preds.append(preds_val)\n",
    "        oof_targets.append(y_val)\n",
    "        scores.append(score)\n",
    "    \n",
    "        ### Predict on test ###\n",
    "        model.load_model(saved_filepath)\n",
    "        preds_test = model.predict(X_test)\n",
    "        test_cv_preds.append(1 / (1 + np.exp(-preds_test)))\n",
    "\n",
    "oof_preds_all = np.concatenate(oof_preds)\n",
    "oof_targets_all = np.concatenate(oof_targets)\n",
    "test_preds_all = np.stack(test_cv_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-20T08:40:20.606367Z",
     "iopub.status.busy": "2020-11-20T08:40:20.605511Z",
     "iopub.status.idle": "2020-11-20T08:40:24.732996Z",
     "shell.execute_reply": "2020-11-20T08:40:24.732121Z"
    },
    "papermill": {
     "duration": 4.339756,
     "end_time": "2020-11-20T08:40:24.733109",
     "exception": false,
     "start_time": "2020-11-20T08:40:20.393353",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mOverall AUC: \u001b[31m0.7510276839965964\n",
      "\u001b[34mAverage CV: \u001b[31m0.01643082481448639\n"
     ]
    }
   ],
   "source": [
    "aucs = []\n",
    "for task_id in range(oof_preds_all.shape[1]):\n",
    "    aucs.append(roc_auc_score(y_true = oof_targets_all[:, task_id],\n",
    "                              y_score = oof_preds_all[:, task_id]\n",
    "                             ))\n",
    "print(f\"{b_}Overall AUC: {r_}{np.mean(aucs)}\")\n",
    "print(f\"{b_}Average CV: {r_}{np.mean(scores)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-20T08:40:25.154105Z",
     "iopub.status.busy": "2020-11-20T08:40:25.153456Z",
     "iopub.status.idle": "2020-11-20T08:40:25.157761Z",
     "shell.execute_reply": "2020-11-20T08:40:25.158237Z"
    },
    "papermill": {
     "duration": 0.21756,
     "end_time": "2020-11-20T08:40:25.158370",
     "exception": false,
     "start_time": "2020-11-20T08:40:24.940810",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(65844, 206)\n",
      "(65844, 206)\n",
      "(65844, 206)\n",
      "22\n"
     ]
    }
   ],
   "source": [
    "print(oof_preds_all.shape)\n",
    "print(oof_targets_all.shape)\n",
    "print(oof_preds_all.shape)\n",
    "print(tabnet_params['seed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-20T08:40:25.583267Z",
     "iopub.status.busy": "2020-11-20T08:40:25.582386Z",
     "iopub.status.idle": "2020-11-20T08:40:27.894493Z",
     "shell.execute_reply": "2020-11-20T08:40:27.893898Z"
    },
    "papermill": {
     "duration": 2.53342,
     "end_time": "2020-11-20T08:40:27.894621",
     "exception": false,
     "start_time": "2020-11-20T08:40:25.361201",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>5-alpha_reductase_inhibitor</th>\n",
       "      <th>11-beta-hsd1_inhibitor</th>\n",
       "      <th>acat_inhibitor</th>\n",
       "      <th>acetylcholine_receptor_agonist</th>\n",
       "      <th>acetylcholine_receptor_antagonist</th>\n",
       "      <th>acetylcholinesterase_inhibitor</th>\n",
       "      <th>adenosine_receptor_agonist</th>\n",
       "      <th>adenosine_receptor_antagonist</th>\n",
       "      <th>adenylyl_cyclase_activator</th>\n",
       "      <th>...</th>\n",
       "      <th>tropomyosin_receptor_kinase_inhibitor</th>\n",
       "      <th>trpv_agonist</th>\n",
       "      <th>trpv_antagonist</th>\n",
       "      <th>tubulin_inhibitor</th>\n",
       "      <th>tyrosine_kinase_inhibitor</th>\n",
       "      <th>ubiquitin_specific_protease_inhibitor</th>\n",
       "      <th>vegfr_inhibitor</th>\n",
       "      <th>vitamin_b</th>\n",
       "      <th>vitamin_d_receptor_agonist</th>\n",
       "      <th>wnt_inhibitor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_0004d9e33</td>\n",
       "      <td>0.001001</td>\n",
       "      <td>0.001180</td>\n",
       "      <td>0.002022</td>\n",
       "      <td>0.019151</td>\n",
       "      <td>0.022228</td>\n",
       "      <td>0.005246</td>\n",
       "      <td>0.002998</td>\n",
       "      <td>0.005494</td>\n",
       "      <td>0.000341</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000791</td>\n",
       "      <td>0.001165</td>\n",
       "      <td>0.003596</td>\n",
       "      <td>0.000863</td>\n",
       "      <td>0.000768</td>\n",
       "      <td>0.000551</td>\n",
       "      <td>0.000530</td>\n",
       "      <td>0.002032</td>\n",
       "      <td>0.002621</td>\n",
       "      <td>0.001774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_001897cda</td>\n",
       "      <td>0.000553</td>\n",
       "      <td>0.000970</td>\n",
       "      <td>0.002050</td>\n",
       "      <td>0.003869</td>\n",
       "      <td>0.002154</td>\n",
       "      <td>0.002155</td>\n",
       "      <td>0.002373</td>\n",
       "      <td>0.010095</td>\n",
       "      <td>0.001831</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000823</td>\n",
       "      <td>0.001038</td>\n",
       "      <td>0.004116</td>\n",
       "      <td>0.000436</td>\n",
       "      <td>0.003736</td>\n",
       "      <td>0.000538</td>\n",
       "      <td>0.003671</td>\n",
       "      <td>0.001173</td>\n",
       "      <td>0.007768</td>\n",
       "      <td>0.003193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_002429b5b</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_00276f245</td>\n",
       "      <td>0.000941</td>\n",
       "      <td>0.001069</td>\n",
       "      <td>0.001757</td>\n",
       "      <td>0.009520</td>\n",
       "      <td>0.014225</td>\n",
       "      <td>0.004072</td>\n",
       "      <td>0.002586</td>\n",
       "      <td>0.004707</td>\n",
       "      <td>0.000272</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000677</td>\n",
       "      <td>0.001883</td>\n",
       "      <td>0.002904</td>\n",
       "      <td>0.014937</td>\n",
       "      <td>0.004340</td>\n",
       "      <td>0.000663</td>\n",
       "      <td>0.001643</td>\n",
       "      <td>0.001733</td>\n",
       "      <td>0.000565</td>\n",
       "      <td>0.001571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_0027f1083</td>\n",
       "      <td>0.001404</td>\n",
       "      <td>0.001343</td>\n",
       "      <td>0.001599</td>\n",
       "      <td>0.015770</td>\n",
       "      <td>0.020870</td>\n",
       "      <td>0.004714</td>\n",
       "      <td>0.003634</td>\n",
       "      <td>0.003071</td>\n",
       "      <td>0.000482</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000753</td>\n",
       "      <td>0.000820</td>\n",
       "      <td>0.002950</td>\n",
       "      <td>0.001631</td>\n",
       "      <td>0.001472</td>\n",
       "      <td>0.000680</td>\n",
       "      <td>0.000892</td>\n",
       "      <td>0.001871</td>\n",
       "      <td>0.000559</td>\n",
       "      <td>0.001550</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  207 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sig_id  5-alpha_reductase_inhibitor  11-beta-hsd1_inhibitor  \\\n",
       "0  id_0004d9e33                     0.001001                0.001180   \n",
       "1  id_001897cda                     0.000553                0.000970   \n",
       "2  id_002429b5b                     0.000000                0.000000   \n",
       "3  id_00276f245                     0.000941                0.001069   \n",
       "4  id_0027f1083                     0.001404                0.001343   \n",
       "\n",
       "   acat_inhibitor  acetylcholine_receptor_agonist  \\\n",
       "0        0.002022                        0.019151   \n",
       "1        0.002050                        0.003869   \n",
       "2        0.000000                        0.000000   \n",
       "3        0.001757                        0.009520   \n",
       "4        0.001599                        0.015770   \n",
       "\n",
       "   acetylcholine_receptor_antagonist  acetylcholinesterase_inhibitor  \\\n",
       "0                           0.022228                        0.005246   \n",
       "1                           0.002154                        0.002155   \n",
       "2                           0.000000                        0.000000   \n",
       "3                           0.014225                        0.004072   \n",
       "4                           0.020870                        0.004714   \n",
       "\n",
       "   adenosine_receptor_agonist  adenosine_receptor_antagonist  \\\n",
       "0                    0.002998                       0.005494   \n",
       "1                    0.002373                       0.010095   \n",
       "2                    0.000000                       0.000000   \n",
       "3                    0.002586                       0.004707   \n",
       "4                    0.003634                       0.003071   \n",
       "\n",
       "   adenylyl_cyclase_activator  ...  tropomyosin_receptor_kinase_inhibitor  \\\n",
       "0                    0.000341  ...                               0.000791   \n",
       "1                    0.001831  ...                               0.000823   \n",
       "2                    0.000000  ...                               0.000000   \n",
       "3                    0.000272  ...                               0.000677   \n",
       "4                    0.000482  ...                               0.000753   \n",
       "\n",
       "   trpv_agonist  trpv_antagonist  tubulin_inhibitor  \\\n",
       "0      0.001165         0.003596           0.000863   \n",
       "1      0.001038         0.004116           0.000436   \n",
       "2      0.000000         0.000000           0.000000   \n",
       "3      0.001883         0.002904           0.014937   \n",
       "4      0.000820         0.002950           0.001631   \n",
       "\n",
       "   tyrosine_kinase_inhibitor  ubiquitin_specific_protease_inhibitor  \\\n",
       "0                   0.000768                               0.000551   \n",
       "1                   0.003736                               0.000538   \n",
       "2                   0.000000                               0.000000   \n",
       "3                   0.004340                               0.000663   \n",
       "4                   0.001472                               0.000680   \n",
       "\n",
       "   vegfr_inhibitor  vitamin_b  vitamin_d_receptor_agonist  wnt_inhibitor  \n",
       "0         0.000530   0.002032                    0.002621       0.001774  \n",
       "1         0.003671   0.001173                    0.007768       0.003193  \n",
       "2         0.000000   0.000000                    0.000000       0.000000  \n",
       "3         0.001643   0.001733                    0.000565       0.001571  \n",
       "4         0.000892   0.001871                    0.000559       0.001550  \n",
       "\n",
       "[5 rows x 207 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_feat = [col for col in df.columns if col not in [\"sig_id\"]]\n",
    "# To obtain the same lenght of test_preds_all and submission\n",
    "test = pd.read_csv(\"../input/lish-moa/test_features.csv\")\n",
    "sig_id = test[test[\"cp_type\"] != \"ctl_vehicle\"].sig_id.reset_index(drop = True)\n",
    "tmp = pd.DataFrame(test_preds_all.mean(axis = 0), columns = all_feat)\n",
    "tmp[\"sig_id\"] = sig_id\n",
    "\n",
    "submission = pd.merge(test[[\"sig_id\"]], tmp, on = \"sig_id\", how = \"left\")\n",
    "submission.fillna(0, inplace = True)\n",
    "submission.to_csv(\"submission.csv\", index = None)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-20T08:40:28.323500Z",
     "iopub.status.busy": "2020-11-20T08:40:28.321014Z",
     "iopub.status.idle": "2020-11-20T08:40:28.326851Z",
     "shell.execute_reply": "2020-11-20T08:40:28.325379Z"
    },
    "papermill": {
     "duration": 0.214846,
     "end_time": "2020-11-20T08:40:28.326992",
     "exception": false,
     "start_time": "2020-11-20T08:40:28.112146",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34msubmission.shape: \u001b[31m(3982, 207)\n"
     ]
    }
   ],
   "source": [
    "print(f\"{b_}submission.shape: {r_}{submission.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.205776,
     "end_time": "2020-11-20T08:40:28.742024",
     "exception": false,
     "start_time": "2020-11-20T08:40:28.536248",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 7948.045477,
   "end_time": "2020-11-20T08:40:30.037412",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-11-20T06:28:01.991935",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
